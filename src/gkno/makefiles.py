#!/bin/bash/python

from __future__ import print_function
from copy import deepcopy
import collections

import fileHandling as fh
import makefileErrors
import stringOperations as stringOps

import json
import os
import sys

# Define a class to hold information about the command line.
class commandLineInformation():
  def __init__(self, graph, superpipeline, struct, task):

    # Store the task and tool.
    self.task     = task
    self.tool     = graph.getGraphNodeAttribute(task, 'tool')
    self.toolData = superpipeline.toolConfigurationData[self.tool]

    # Store if the task is greedy or consolidates divisions.
    self.isGreedy      = graph.getGraphNodeAttribute(task, 'isGreedy')
    self.isConsolidate = graph.getGraphNodeAttribute(task, 'isConsolidate')

    # Determine the number of command lines to be created for the task. This can be determined by finding
    # the phase in which the task resides in the pipeline execution structure, and then determining the
    # number of subphases and divisions within the phase. The total number of command lines is equal to the
    # product of these two values.
    self.phase              = struct.task[task]
    self.numberSubphases    = struct.phaseInformation[self.phase].numberSubphases
    self.numberDivisions    = struct.phaseInformation[self.phase].numberDivisions
    self.numberCommandLines = self.numberSubphases * self.numberDivisions

    # Get the executable information.
    self.executable = self.toolData.executable
    self.modifier   = self.toolData.modifier
    self.path       = self.toolData.path
    self.precommand = self.toolData.precommand

    # Get the argument delimiter for this tool.
    self.delimiter = self.toolData.delimiter

    # Define and store the path to the executable.
    self.toolID = str(self.tool.upper() + '-PATH')

    # Store the command lines for this task. This is indexed by the subphase and the division. Store
    # the dependencies, intermediates, output files and files for standard out to write to, for each
    # command line with the same structure.
    self.commands      = {}
    self.dependencies  = {}
    self.intermediates = {}
    self.outputs       = {}
    self.stdouts       = {}
    for i in range(1, self.numberSubphases + 1):
      self.commands[i]      = {}
      self.dependencies[i]  = {}
      self.intermediates[i] = {}
      self.outputs[i]       = {}
      self.stdouts[i]       = {}
      for j in range(1, self.numberDivisions + 1):
        self.commands[i][j]      = []
        self.dependencies[i][j]  = []
        self.intermediates[i][j] = []
        self.outputs[i][j]       = []
        self.stdouts[i][j]       = str('\t>> $(STDOUT) \\')

# Define a class that is a data structure for holding information for tasks that are piped
# together.
class streamingInformation:
  def __init__(self):
    self.commands       = []
    self.dependencies   = []
    self.intermediates  = []
    self.outputs        = []
    self.streamedFiles  = []
    self.tasks          = []

# Define a class to build and manipulate makefiles.
class makefiles:
  def __init__(self):

    # Handle errors associated with makefile construction.
    self.errors = makefileErrors.makefileErrors()

    # Store the paths of all the tools executed in the pipeline.
    self.toolPaths = {}

    # Store information including command lines, dependencies and outputs for each task.
    self.executionInfo = {}

    # Record if multiple makefiles are to be generated.
    self.isMultipleMakefiles = False

    # Store the user specified ID to add to all makefile filesnames.
    self.makefileId = None

    # Store the name of the makefile and filehandle if only a single file is being produced.
    self.singleFilehandle = None
    self.singleFilename   = None

    # Create a dictionary to store the names of all the created makefiles. The dictionary
    # is keyed on the phase, subphase and the division.
    self.makefileNames   = {}
    self.makefilehandles = {}

    # Store the outputs generated by each makefile.
    self.makefileOutputs = {}

  # Generate the command lines associated with a task.
  def generateCommandLines(self, graph, superpipeline, struct):

    # Loop over all the tasks in the pipeline, generating the command lines for each task.
    for task in graph.workflow:

      # Get the tool used to run the task and the data contained in the configuration file.
      tool     = graph.getGraphNodeAttribute(task, 'tool')
      toolData = superpipeline.toolConfigurationData[tool]

      # Determine whether the input or the output from this task are streams.
      isInputStream  = graph.getGraphNodeAttribute(task, 'isInputStream')
      isOutputStream = graph.getGraphNodeAttribute(task, 'isOutputStream')

      # Loop over all of the nodes and get the arguments that are going to be used and the
      # node IDs to which they connect. This will then be used to allow the arguments to 
      # be parsed in the order specified.
      inputArguments  = self.getArguments(graph, task, graph.getInputFileNodes(task), isInput = True)
      optionArguments = self.getArguments(graph, task, graph.getOptionNodes(task), isInput = True)
      outputArguments = self.getArguments(graph, task, graph.getOutputFileNodes(task), isInput = False)

      # Check if the tool arguments need to be included in a defined order.
      argumentOrder = toolData.argumentOrder
      if not argumentOrder: argumentOrder = inputArguments.keys() + optionArguments.keys() + outputArguments.keys()

      # Generate a data structure for building the command line.
      data = commandLineInformation(graph, superpipeline, struct, task)
  
      # Store the tools path in the global makefiles dictionary toolPaths. If the path is listed
      # as 'none', do not include the path.
      if data.tool not in self.toolPaths and data.path != 'none': self.toolPaths[data.tool] = str(data.toolID + '=$(TOOL_BIN)/' + data.path)
  
      # The output of the method is a list of command lines, one command line for each execution
      # of the task. Each command line is itself a list of the command line executable and arguments.
      # First determine the command line executable.
      path = ' ' if data.path == 'none' else ' $(' + data.toolID + ')/'
      command = str(data.precommand + path + data.executable + ' ' + data.modifier).rstrip(' ').strip(' ')
  
      # Add the executable to the command lines and initialise the lists of dependencies and outputs
      # to have the same length as the commands.
      for i in range(1, data.numberSubphases + 1):
        for j in range(1, data.numberDivisions + 1):
          if not isInputStream: data.commands[i][j].append('\t@' + command + ' \\')
          else: data.commands[i][j].append('\t' + command + ' \\')

      # Loop over the argument order for the tool, getting information from the nodes in the correct
      # order. The argument order is populated with the arguments in random order if the order wasn't
      # specified in the configuration file.
      for argument in argumentOrder:
        if argument in optionArguments:
          for nodeId in optionArguments[argument]: self.addOption(graph, task, data, nodeId)
        if argument in inputArguments:
          for nodeId in inputArguments[argument]: self.addInput(graph, task, data, nodeId)
        if argument in outputArguments:
          for nodeId in outputArguments[argument]: self.addOutput(graph, task, data, nodeId)

      # Finish the command lines with calls to write to stdout and stdin and indicating that the task is complete.
      # These values are modified based on whether the task is outputting to a stream or not.
      for i in range(1, data.numberSubphases + 1):
        for j in range(1, data.numberDivisions + 1):
          if isOutputStream:
            data.commands[i][j].append('\t2>> $(STDERR) \\')
            data.commands[i][j].append('\t| \\')
  
          else:
            data.commands[i][j].append(data.stdouts[i][j])
            data.commands[i][j].append('\t2>> $(STDERR)')
            data.commands[i][j].append('\t@echo -e "completed successfully."')
            data.commands[i][j].append('')

      # Store the command lines for the task.
      self.executionInfo[task] = data

  # Find all the arguments for a task.
  def getArguments(self, graph, task, nodeIds, isInput):
    arguments = {}
    for nodeId in nodeIds:

      # If the node is a child, ignore it. In order to ensure that filenames will appear in the correct order of divisions,
      # the parent node must appear first in the list, followed by the children in division order.
      if not graph.getGraphNodeAttribute(nodeId, 'isChild'):
        if isInput: argument = graph.getArgumentAttribute(nodeId, task, 'longFormArgument')
        else: argument = graph.getArgumentAttribute(task, nodeId, 'longFormArgument')
  
        if argument in arguments: arguments[argument].append(nodeId)
        else: arguments[argument] = [nodeId]

        # If this is an input and a parent node, add the children to the list in the correct order.
        if isInput and graph.getGraphNodeAttribute(nodeId, 'isParent'):
          for child in graph.getGraphNodeAttribute(nodeId, 'children'): arguments[argument].append(child)

    # Return the arguments.
    return arguments

  # Add option values to the command lines.
  def addOption(self, graph, task, data, nodeId):

    # Get the argument, values and data type for the option node.
    argument = self.getToolArgument(graph, task, nodeId, isInput = True)
    values   = graph.getGraphNodeAttribute(nodeId, 'values')
    dataType = graph.getArgumentAttribute(nodeId, task, 'dataType')

    # Determine if this option can be specified multiple times on the command line, or if this
    # option is used to create divisions..
    isAllowMultipleValues = graph.getArgumentAttribute(nodeId, task, 'allowMultipleValues')
    isCreateDivision      = graph.getGraphNodeAttribute(nodeId, 'isCreateDivision')

    # If the argument is a flag, it cannot be given multiple values.
    if dataType == 'flag' and len(values) > 1: print('ERROR - makefiles.addOption - 3'); exit(1)

    # Regardless of the number of values supplied, each subphase needs to receive the same values.
    # Any differences between command lines would occur for multiple divisions. So, loop over all
    # divisions and apply the same command line to each subphase within the division.
    for i in range(1, data.numberDivisions + 1):
      lines = []

      # If the option creates the divisions, create the line based on the ith value. 
      if isCreateDivision:
        #TODO ERROR
        if len(values) != data.numberDivisions: print('ERROR - makefiles.addOption - 1'); exit(1)
        lineValue = self.getValue(graph, nodeId, task, values[i - 1], isInput = True, isStub = False, stubExtension = None)
        lines.append(self.buildLine(argument, data.delimiter, lineValue))

      # If this option does not create the divisions, but there are multiple values, they must all be applied on the
      # same command line. Again, this cannot be a flag.
      elif len(values) > 1:

        # Check that the option is permitted to be applied multiple times.
        if not isAllowMultipleValues: print('ERROR - makefiles.addOption - 2', argument, len(values)); exit(1)
        for value in values:
          lineValue = self.getValue(graph, nodeId, task, value, isInput = True, isStub = False, stubExtension = None)
          lines.append(self.buildLine(argument, data.delimiter, lineValue))

      # If there is only a single value, build the line considering if this is a flag.
      else:

        # If the option is a flag, there is no value to output, so set this to a blank.
        if dataType == 'flag':
          lineValue = ''
          if values[0] != 'set': argument = ''

        # If the value is set, the flag should be set on the command line, otherwise, this should be left blank.
        else: lineValue = self.getValue(graph, nodeId, task, values[0], isInput = True, isStub = False, stubExtension = None)

        # Only add the line to the lines if the flag is set.
        line = self.buildLine(argument, data.delimiter, lineValue)
        if line: lines.append(line)

      # Add the options to the command lines for each subphase.
      for j in range(1, data.numberSubphases + 1): data.commands[j][i].extend(lines)

  # Add input files to the command line.
  def addInput(self, graph, task, data, nodeId):

    # Get the argument, values and data type for the option node.
    argument = self.getToolArgument(graph, task, nodeId, isInput = True)
    values   = graph.getGraphNodeAttribute(nodeId, 'values')
    dataType = graph.getArgumentAttribute(nodeId, task, 'dataType')

    # Determine if this option can be specified multiple times on the command line and if the task is listed
    # as being greedy.
    isAllowMultipleValues = graph.getArgumentAttribute(nodeId, task, 'allowMultipleValues')
    isGreedy              = graph.getGraphNodeAttribute(task, 'isGreedy')

    # Check if this node contains intermediate files.
    #isIntermediate = graph.getGraphNodeAttribute(nodeId, 'isIntermediate')
    isIntermediate = True if graph.getGraphNodeAttribute(nodeId, 'deleteAfterTask') == task else False

    # Determine if this is a stub.
    isStub        = graph.getArgumentAttribute(nodeId, task, 'isStub')
    stubExtension = graph.getArgumentAttribute(nodeId, task, 'stubExtension')

    # Determine if this argument is for a stream.
    isStream = graph.getArgumentAttribute(nodeId, task, 'isStream')

    # Convert the values into the form required on the command line.
    if isStream: lineValues = [self.getStreamValue(graph, nodeId, task, value, True, isStub) for value in values]
    else: lineValues = [self.getValue(graph, nodeId, task, value, True, isStub, stubExtension) for value in values]

    # If this task is greedy, check that the argument allows multiple values to be set and that there is only a single
    # subphase. Then create the command line.
    if isGreedy:
      #TODO ERROR
      if len(values) > 1:
        if not isAllowMultipleValues: print('ERROR - makefiles.addInput - 1'); exit(1)
        if data.numberSubphases > 1: print('ERROR - makefiles.addInput - 2'); exit(1)

    # Regardless of the number of values supplied, each division needs to receive the same values.
    # Each subphase operates on either all the input files, or a subset, but if there are divisions,
    # each division has the same input files. The differences in the divisions come from different
    # supplied options.
    for subphase in range(1, data.numberSubphases + 1):
      lines = []

      # If this task is greedy, check that the argument allows multiple values to be set and that there is only a single
      # subphase. Then create the command line.
      if isGreedy or len(lineValues) == 1:

        # Loop over the values and add to the command line.
        for value in lineValues:
          lineValue = self.getValue(graph, nodeId, task, value, isInput = True, isStub = isStub, stubExtension = stubExtension)
          line      = self.buildLine(argument, data.delimiter, lineValue)
          if line: lines.append(line)

      # If the task isn't greedy and has multiple values, each value is used for a seperate subphase.
      elif len(lineValues) > 1:
        lineValue = self.getValue(graph, nodeId, task, lineValues[subphase - 1], isInput = True, isStub = isStub, stubExtension = stubExtension)
        line      = self.buildLine(argument, data.delimiter, lineValue)
        if line: lines.append(line)

      # Add the options to the command lines for each subphase.
      for division in range(1, data.numberDivisions + 1):
        data.commands[subphase][division].extend(lines)

        # Add the files to the dependencies or outputs for the command line (if not being streamed).
        if not isStream:
          if isGreedy and len(lineValues) > 1:
            for value in values: data.dependencies[subphase][division].append(str(value))
          elif len(values) > 1: data.dependencies[subphase][division].append(str(values[subphase - 1]))
          else: data.dependencies[subphase][division].append(str(values[0]))
    
          # Add to the intermediates if necessary.
          if isIntermediate:
            if isGreedy and len(values) > 1:
              for value in values:
                if str(value) not in data.intermediates[subphase][division]: data.intermediates[subphase][division].append(str(value))
            elif len(values) > 1:
              if str(values[subphase - 1]) not in data.intermediates[subphase][division]: data.intermediates[subphase][division].append(str(values[subphase - 1]))
            else:
              if str(values[0]) not in data.intermediates[subphase][division]: data.intermediates[subphase][division].append(str(values[0]))

  # Add input files to the command line.
  def addOutput(self, graph, task, data, nodeId):

    # Get the argument, values and data type for the option node.
    argument = self.getToolArgument(graph, task, nodeId, isInput = False)
    values   = graph.getGraphNodeAttribute(nodeId, 'values')
    dataType = graph.getArgumentAttribute(task, nodeId, 'dataType')

    # Check if this task has children. If so, the outputs for the different subphases will be attached to the child nodes.
    isParent = graph.getGraphNodeAttribute(nodeId, 'isParent')
    children = graph.getGraphNodeAttribute(nodeId, 'children')

    # Check if this node contains intermediate files.
    #isIntermediate = graph.getGraphNodeAttribute(nodeId, 'isIntermediate')
    isIntermediate = True if graph.getGraphNodeAttribute(nodeId, 'deleteAfterTask') == task else False

    # Determine if this is a stub.
    isStub         = graph.getArgumentAttribute(task, nodeId, 'isStub')
    stubExtension  = graph.getArgumentAttribute(task, nodeId, 'stubExtension')
    includeStubDot = graph.getArgumentAttribute(task, nodeId, 'includeStubDot')
    isPrimaryNode  = graph.getArgumentAttribute(task, nodeId, 'primaryStubNode')

    # Determine if this argument is for a stream.
    isStream = graph.getArgumentAttribute(task, nodeId, 'isStream')

    # Convert the values into the form required on the command line.
    if isStream: lineValues = [self.getStreamValue(graph, task, nodeID, value, False, isStub) for value in values]
    else: lineValues = [self.getValue(graph, task, nodeId, value, False, isStub, stubExtension) for value in values]

    # If this is a parent node, then the task has been split into divisions. The parent file node and it's children each
    # correspond to a division. Thus the values contained in them are for each subphase with the division. Begin by looping
    # over the values in the parent node. This corresponds to the first division, then each value is for each of the
    # subphases. Then loop over the children and populate the subphase outputs for each division.
    #
    # Deal with the first division. If there are multiple divisions, this is the values from the parent node. If there is
    # only a single division, this is the only node that exists.
    for subphase, value in enumerate(values):
      if isStub and not isPrimaryNode: line = None
      else:
        lineValue = self.getValue(graph, task, nodeId, value, isInput = False, isStub = isStub, stubExtension = stubExtension)
        line      = self.buildLine(argument, data.delimiter, lineValue)
      if line:

        # If this task outputs to stdout, update the stdouts data structure,
        if line.startswith('\t>>'): data.stdouts[subphase + 1][1] = str(line)
        else: data.commands[subphase + 1][1].append(line)

      # Add the files to the dependencies or outputs for the command line (do not add the values to the list of
      # inputs and dependencies if the files are being streamed).
      if not isStream:
        data.outputs[subphase + 1][1].append(str(value))

        # If this is an intermediate file, add to the list of intermediate files.
        if isIntermediate and str(value) not in data.intermediates[subphase + 1][1]: data.intermediates[subphase + 1][1].append(str(value))

    # If there are multiple divisions, values for division 2 onwards are stored in the child nodes which are dealt with here.
    if isParent:
      for child in children:
        division = graph.getGraphNodeAttribute(child, 'divisionID') + 1
        lines    = []
        for subphase, value in enumerate(graph.getGraphNodeAttribute(child, 'values')):
          if isStub and not isPrimaryNode: line = None
          else:
            lineValue = self.getValue(graph, task, nodeId, value, isInput = False, isStub = isStub, stubExtension = stubExtension)
            line      = self.buildLine(argument, data.delimiter, lineValue)
          if line: data.commands[subphase + 1][division].append(line)

          # Add the files to the dependencies or outputs for the command line (do not add the values to the list of
          # inputs and dependencies if the files are being streamed).
          if not isStream:
            data.outputs[subphase + 1][division].append(str(value))
    
            # If this is an intermediate file, add to the list of intermediate files.
            if isIntermediate and str(value) not in data.intermediates[subphase + 1][division]: data.intermediates[subphase + 1][division].append(str(value))

#FIXME REMOVE WHEN STUBS ARE HANDLED. USE THIS TO FIGURE OUT HOW TO USED THEM.
#  # Add input or output files to the command line (this method is only called for nodes that are not multinodes).
#  def addFiles(self, graph, task, data, nodeId, isInput):
#
#    # Set the source and target for the edge. This depends on whether the file is an input to or an output from 
#    # the task.
#    if isInput:
#      source = nodeId
#      target = task
#    else:
#      source = task
#      target = nodeId
#
#    # Get the argument and values for the file node.
#    argument = self.getToolArgument(graph, task, nodeId, isInput)
#    values   = graph.getGraphNodeAttribute(nodeId, 'values')
#
#    # Check if this task generates multiple nodes.
#    isGeneratesMultipleNode = graph.getGraphNodeAttribute(task, 'generateMultipleOutputNodes')
#    isConsolidate           = graph.getGraphNodeAttribute(task, 'consolidate')
#
#    # Check if this node is associated with intermediate files.
#    isIntermediate = True if graph.getGraphNodeAttribute(nodeId, 'deleteAfterTask') == task else False
#
#    # Determine if this argument is for a stream.
#    isStream = graph.getArgumentAttribute(source, target, 'isStream')
#
#    # Determine if this is a stub and if so, get the extension used for this node.
#    isStub         = graph.getArgumentAttribute(source, target, 'isStub')
#    stubExtension  = graph.getArgumentAttribute(source, target, 'stubExtension')
#    includeStubDot = graph.getArgumentAttribute(source, target, 'includeStubDot')
#
#    # Convert the values into the form required on the command line.
#    if isStream: lineValues = [self.getStreamValue(graph, source, target, value, isInput, isStub) for value in values]
#    else: lineValues = [self.getValue(graph, source, target, value, isInput, isStub, stubExtension) for value in values]
#
#    # If there is only a single file, attach to all of the command lines.
#    if len(lineValues) == 1:
#
#      # Build the tool specific command line.
#      line = self.buildLine(argument, data.delimiter, lineValues[0])
#      for i in range(0, data.noCommandLines):
#
#        # If this task outputs to stdout, put the values into a structure to return.
#        if line:
#          if line.startswith('\t>>'): data.stdouts[i] = str(line)
#          else: data.commands[i].append(line)
#
#        # Add the files to the dependencies or outputs for the command line, unless this is a stream.
#        if not isStream:
#
#          # If this is a stub, add the extension to the value prior to inclusion in the outputs/dependencies.
#          if isStub: modifiedValue = self.addStubExtension(values[0], stubExtension, includeStubDot)
#          else: modifiedValue = values[0]
#
#          if isInput: data.dependencies[i].append(str(modifiedValue))
#          else: data.outputs[i].append(str(modifiedValue))
#
#          # Add to the intermediates if necessary.
#          if isIntermediate and str(modifiedValue) not in data.intermediates[i]: data.intermediates[i].append(str(modifiedValue))
#
#    # If this is a greedy task, add all the values to each command line.
#    elif isInput and data.isGreedy:
#      for i in range(0, data.noCommandLines):
#        for value, lineValue in zip(values, lineValues):
#
#          # Build the tool specific command line.
#          line = self.buildLine(argument, data.delimiter, lineValue)
#          if line: data.commands[i].append(line)
#
#          # Add the files to the dependencies or outputs for the command line (if not being streamed).
#          if not isStream:
#            data.dependencies[i].append(str(value))
#
#            # Add to the intermediates if necessary.
#            if isIntermediate and str(value) not in data.intermediates[i]: data.intermediates[i].append(str(value))
#
#    # If this is an input for a task that generates multiple nodes, and there are as many values as
#    # there are subphases, add the files in the correct order. If there are N divisions, the first
#    # file is used for the first subphase and so the first N command lines etc.
#    elif isInput and isGeneratesMultipleNode:
#      i = 0
#      for value, lineValue in zip(values, lineValues):
#
#        # Construct the tool specific command line.
#        line = self.buildLine(argument, data.delimiter, lineValue)
#        for j in range(0, data.noDivisions):
#          if line: data.commands[i].append(line)
#
#          # Add the files to the dependencies or outputs for the command line (if not being streamed).
#          if not isStream:
#            data.dependencies[i].append(str(value))
#  
#            # Add to the intermediates if necessary.
#            if isIntermediate and str(value) not in data.intermediates[i]: data.intermediates[i].append(str(value))
#
#          # Increment the counter.
#          i += 1
#
#    # If this is a consolidation node. In this case, all of the inputs files are being used in the
#    # same command line and the number of command lines is reduced down to the number of subphases,
#    # e.g. the number of divisions is reset to one. If this is the case, consolidate the command lines.
#    elif not isInput and isConsolidate:
#      i = 0
#      for value, lineValue in zip(values, lineValues):
#
#        # If there are multiple tasks feeding into a single task to be consolidated, the outputs for this task
#        # cannot be streamed.
#        line = self.buildLine(argument, data.delimiter, lineValue)
#
#        # If the task outputs to stdout, store the values to return.
#        if line:
#          if line.startswith('\t>>'): data.stdouts[i] = str(line)
#          else: data.commands[i].append(line)
#
#        # Add the files to the dependencies or outputs for the command line (if not streamed).
#        if not isStream:
#          data.outputs[i].append(str(value))
#  
#          # Add to the intermediates if necessary.
#          if isIntermediate and str(value) not in data.intermediates[i]: data.intermediates[i].append(str(value))
#
#        # Increment the counter.
#        i += 1
#
#    # If there are as many files as there are divisions, add the files in the correct order.
#    elif not isGeneratesMultipleNode and len(values) == data.noDivisions:
#      for i, value in enumerate(values):
#        lineValue = lineValues[i]
#
#        # Build the tool specific command line.
#        line = self.buildLine(argument, data.delimiter, lineValue)
#
#        # If the task outputs to stdout, store the values to return.
#        if line:
#          if line.startswith('\t>>'):  data.stdouts[i] = str(line)
#          else: data.commands[i].append(line)
#
#        # Add the files to the dependencies or outputs for the command line (if not being streamed).
#        if not isStream:
#          if isInput: data.dependencies[i].append(str(value))
#          else: data.outputs[i].append(str(value))
#  
#          # Add to the intermediates if necessary.
#          if isIntermediate and str(value) not in data.intermediates[i]: data.intermediates[i].append(str(value))
#
#    # If there are a different number of files to subphases, there is a problem.
#    #TODO ERROR
#    else: print('error - makefileerrors.addfiles'); exit(1)

  # Check if the value has the given extension and, if not, add it.
  def addStubExtension(self, value, extension, includeStubDot):
    if value.endswith(extension): return value
    else:
      updatedValue = str(value + '.' + extension) if includeStubDot else str(value + extension)
      return updatedValue

  # If a single makefile is being generated, set the name and open the file.
  def openSingleMakefile(self, pipeline):
    self.singleFilename = str(pipeline + '-' + self.makefileId) if self.makefileId else str(pipeline)

    # Add a random string to the makefile name. This ensures that if gkno has been executed in a loop,
    # multiple runs of gkno in the same directory for the same pipeline will create makefiles with
    # unique names.
    self.singleFilename += str('.' + stringOps.getRandomString(8) + '.make')

    # Open the file for writing.
    self.singleFilehandle = fh.fileHandling.openFileForWriting(self.singleFilename)

  # Add header text to the file.
  def addHeader(self, filehandle, commitID, date, version, pipeline, sourcePath, toolsPath, resourcesPath, name):

    # Add basic text about the gkno version.
    print('### gkno makefile', file = filehandle)
    print('### Generated using gkno version: ', version, ' (', date, ')', sep = '', file = filehandle)
    print('### gkno commit: ', commitID, sep = '', file = filehandle)
    print('### Pipeline: ', pipeline, sep = '', file = filehandle)
    print(file = filehandle)
    print('### Set the shell to bash.', file = filehandle)
    print('SHELL=/bin/bash', file = filehandle)
    print(file = filehandle)

    # Include the paths to tools and resources.
    print('### Paths to tools and resources.', file = filehandle)
    print('GKNO_PATH=', sourcePath, sep = '', file = filehandle)
    print('TOOL_BIN=', toolsPath, sep = '', file = filehandle)
    print('RESOURCES=', resourcesPath, sep = '', file = filehandle)
    print('MAKEFILE_ID=', name.rsplit('.make', 1)[0], sep = '', file = filehandle)
    print(file = filehandle)

    # Define the stdout and stderr.
    print('### Standard output and error files.', file = filehandle)
    print('STDOUT=$(PWD)/$(MAKEFILE_ID).stdout', sep = '', file = filehandle)
    print('STDERR=$(PWD)/$(MAKEFILE_ID).stderr', sep = '', file = filehandle)
    print('COMPLETE_OK=$(PWD)/$(MAKEFILE_ID).ok', sep = '', file = filehandle)
    print(file = filehandle)

    # Remove file on failed execution.
    print('### If the pipeline terminates unexpectedly, delete all files that were in', file = filehandle)
    print('### the process of being generated.', file = filehandle)
    print('.DELETE_ON_ERROR:', file = filehandle)
    print(file = filehandle)

    # The paths to the executables are added by phase later.
    print('### Executable paths.', file = filehandle)

  # If a single makefile is being output, find all the unique tools used in the pipeline.
  def addUniqueExecutables(self, filehandle, graph, struct):
    allTools = []

    # Loop over all phases and all contained task and identify all tools.
    for phase in struct.phaseInformation:
      for task in struct.phaseInformation[phase].tasks:
        tool = graph.getGraphNodeAttribute(task, 'tool')
        if tool in self.toolPaths: allTools.append(self.toolPaths[tool])
 
    # Having colleted all tools, remove duplicates and write to file.
    for tool in list(set(allTools)): print(str(tool), file = filehandle)
    print(file = filehandle)

  # List phony arguments. This is used solely for the file created on successful execution of the pipeline.
  def addPhony(self, filehandle, name):
    print('### List all PHONY targets. These are targets that are not actual files.', file = filehandle)
    print('.PHONY: DELETE_COMPLETE_OK', name, file = filehandle)
    print(file = filehandle)

  # Get the intermediate and output files for the whole pipeline.
  def getAllOutputs(self, filehandle, filename, struct):

    # Loop over all the phases, subphases and divisions.
    allIntermediates = []
    allOutputs       = []
    for phase in struct.phaseInformation:
      subphases = struct.phaseInformation[phase].numberSubphases
      divisions = struct.phaseInformation[phase].numberDivisions
      for task in struct.phaseInformation[phase].tasks:
        for subphase in range(1, subphases + 1):
          for division in range(1, divisions + 1):
            allOutputs.extend(self.executionInfo[task].outputs[subphase][division])
            allIntermediates.extend(self.executionInfo[task].intermediates[subphase][division])

    # Determine if there are duplicate output files.
    duplicates = [x for x, y in collections.Counter(allOutputs).items() if y > 1]
    if len(duplicates) != 0: self.errors.duplicateOutputFiles(duplicates)

    # Remove output files that are also marked as intermediates.
    allOutputs = list(set(allOutputs) - set(allIntermediates))

    # Add the intermediate and output files.
    self.addIntermediateFiles(allIntermediates, filename, filehandle)
    self.addOutputFiles(allOutputs, filehandle)

    # Return a list of final outputs.
    return allOutputs

  # Add intermediate files to the makefile.
  def addIntermediateFiles(self, intermediates, filename, filehandle):

    # Write intermediate files to the makefile header. Files marked as intermediate are removed during
    # execution of the pipeline. By being marked as intermediate, reexecution of the pipeline will not
    # commence to regenerate the intermediate files.
    print('### The following files are intermediates. If the pipeline is rerun, rules for creating', file = filehandle)
    print('### will not be rerun unless files prior to these rules have been updated.', file = filehandle)
    print('.INTERMEDIATE: ', filename, end = ' ', file = filehandle)

    # Add all the intermediates to the makefile.
    for intermediate in intermediates: print(intermediate, end = ' ', file = filehandle)
    print(file = filehandle)
    print(file = filehandle)

  # Add output files to the makefile.
  def addOutputFiles(self, outputs, filehandle):

    # List all the output files created by this makefile.
    print('### List all of the files that are required outputs of the pipeline.', file = filehandle)
    print('all: $(COMPLETE_OK) ', end = '', file = filehandle)

    # Add all the output files to the makefile.
    for output in outputs: print(output, end = ' ', file = filehandle)
    print(file = filehandle)
    print(file = filehandle)

  # Prior to pipeline execution, remove the 'ok' file prodiced by a previous successful execution.
  def removeOk(self, filehandle):
    print('### Remove the file indicating successful completion of the pipeline. This file needs', file = filehandle)
    print('### to be recreated if the pipeline is rerun to indicate successful completion.', file = filehandle)
    print('DELETE_COMPLETE_OK:', file = filehandle)
    print('\t@rm -f $(COMPLETE_OK)', file = filehandle)
    print(file = filehandle)

  # Add the command lines to the makefiles.
  def addCommandLines(self, filehandle, filename, graph, struct, phase, subphase, division):

    # Loop over the tasks for this makefile adding the command lines.
    for task in struct.phaseInformation[phase].tasks:
      isInputStream  = graph.getGraphNodeAttribute(task, 'isInputStream')
      isOutputStream = graph.getGraphNodeAttribute(task, 'isOutputStream')

      # If this task outputs to a stream, no information should be written to the makefiles at this point.
      # All of the tasks that are part of the stream should be processed, so that the list of dependencies
      # and outputs can be constructed properly. If the task does not accept an input stream, then this is
      # the first task in the set of piped tools, so a data structure should be initialised.
      if isOutputStream:
        if not isInputStream: info = streamingInformation()
        self.storeStreamingTaskInformation(info, task, subphase, division, isLast = False)

      # If this task accepts an input stream and isn't outputting to a stream, all of the stored information
      # as well as the information for this task can be written to file.
      elif isInputStream:
        self.storeStreamingTaskInformation(info, task, subphase, division, isLast = True)
        self.writeStreamingInformation(filehandle, graph, info, subphase, division)

      # If this does not accept a stream or output to a stream, just write the information to the makefile.
      else: self.writeStandardInformation(filehandle, filename, graph, task, subphase, division)

  # Update the stored information for tasks piped together.
  def storeStreamingTaskInformation(self, info, task, subphase, division, isLast):

    # Add this task to the list of tasks that are streamed together.
    info.tasks.append(task)

    # Update the list of task dependencies. This is all of the dependencies for the current
    # task minus any files that are streamed.
    for dependency in self.executionInfo[task].dependencies[subphase][division]:
      if dependency not in info.streamedFiles and dependency not in info.dependencies: info.dependencies.append(dependency)

    # Now loop over all of the outputs for the task. If the output file is being piped, this
    # should not be included in the list of outputs.
    # FIXME FOR NOW ASSUMING THAT ALL OUTPUTS ARE STREAMED.
    if isLast:
      for output in self.executionInfo[task].outputs[subphase][division]: info.outputs.append(output)
    else:
      for output in self.executionInfo[task].outputs[subphase][division]: info.streamedFiles.append(output)

    # Loop over all of the intermediate files (e.g. the files that can be deleted after this task is
    # complete) and store these files. These will be deleted at the end of the piped tasks.
    for intermediate in self.executionInfo[task].intermediates[subphase][division]:
      if intermediate not in info.streamedFiles and intermediate not in info.intermediates: info.intermediates.append(intermediate)

    # Finally, store the command line for the task.
    for line in self.executionInfo[task].commands[subphase][division]: info.commands.append(line)

  # Write information to the makefile for a set of piped tasks.
  def writeStreamingInformation(self, filehandle, graph, info, subphase, division):
    print('### Command line information for the following piped tasks:', file = filehandle)
    print('### ', end = '', file = filehandle)
    for i in range(0, len(info.tasks) - 1): print(info.tasks[i], end = ', ', file = filehandle)
    print(info.tasks[-1], '...', sep = '', file = filehandle)

    # Only include the first output in the rule. If there are additional outputs, these are handled after
    # the rule in the makefile.
    print(info.outputs[0], ':', sep = '', end = ' ', file = filehandle)
    for dependency in info.dependencies: print(dependency, end = ' ', file = filehandle)
    print(file = filehandle)
  
    # Print to screen the tasks being executed.
    print('\t@echo -e "Executing tasks: ', end = '', file = filehandle)
    for i in range(0, len(info.tasks) - 1): print(info.tasks[i], end = ', ', file = filehandle)
    print(info.tasks[-1], '...\c"', sep = '', file = filehandle)
  
    # Print the command line.
    for line in info.commands: print(line, file = filehandle)
  
    # Include an additional rule if the task created multiple output files.
    # FIXME
    if len(info.outputs) > 1: self.multipleOutputFiles(filehandle, filename, info, subphase, division)

    # If any files are to be deleted after this task, delete them.
    if info.intermediates:
      print('\t### Delete intermediate files that are no longer required.', file = filehandle)
      for intermediate in info.intermediates: print('\t@rm -f ', intermediate, sep = '', file = filehandle)
      print(file = filehandle)

  # Write information to the makefile for a task with no streaming.
  def writeStandardInformation(self, filehandle, filename, graph, task, subphase, division):
    print('### Command line information for the following task:', file = filehandle)
    print('### ', task, ' (', graph.getGraphNodeAttribute(task, 'tool'), ')', sep = '', file = filehandle)
  
    # Only include the first output in the rule. If there are additional outputs, these are handled after
    # the rule in the makefile.
    print(self.executionInfo[task].outputs[subphase][division][0], ':', sep = '', end = ' ', file = filehandle)
    for dependency in self.executionInfo[task].dependencies[subphase][division]: print(dependency, end = ' ', file = filehandle)
    print(file = filehandle)

    # Print to screen the task being executed.
    print('\t@echo -e "Executing task: ', task, '...\c"', sep = '', file = filehandle)
  
    # Print the command line.
    for line in self.executionInfo[task].commands[subphase][division]: print(line, file = filehandle)

    # Include an additional rule if the task created multiple output files.
    if len(self.executionInfo[task].outputs[subphase][division]) > 1:
      self.multipleOutputFiles(filehandle, filename, self.executionInfo[task], subphase, division)

    # If any files are to be deleted after this task, delete them.
    if self.executionInfo[task].intermediates[subphase][division]:
      print('### Delete intermediate files that are no longer required.', file = filehandle)
      print('\t@echo -e "Deleting temporary files...\\c"', file = filehandle)
      for intermediate in self.executionInfo[task].intermediates[subphase][division]: print('\t@rm -f ', intermediate, sep = '', file = filehandle)
      print('\t@echo -e "complete."', file = filehandle)
      print(file = filehandle)

  # output is included in the rule for the additional task.
  def multipleOutputFiles(self, filehandle, filename, data, subphase, division):
    print('### Rule for checking that all outputs of previous task exist.', file = filehandle)
    for counter in range(1, len(data.outputs[subphase][division]) - 1):
      print(data.outputs[subphase][division][counter], end = ' ', file = filehandle)
    print(data.outputs[subphase][division][-1], end = ': ', file = filehandle)
    for dependency in data.dependencies[subphase][division]: print(dependency, end = ' ', file = filehandle)

    # Add the primaryOutput to the list of dependencies. This is the file that is listed as the output for
    # the rule. If running with multiple threads and none of the files exist, the original rule is executed
    # since the output file does not exist. This rule for the additional outputs is the executed in parallel
    # since none of these additional files exist either. By including the primaryOutput as a dependency, we
    # ensure that the original rule gets to run first and this check isn't performed until it has been
    # completed.
    print(data.outputs[subphase][division][0], file = filehandle)
    print('\t@if test -f $@ || test -d $@; then \\', file = filehandle)
    print('\t  touch $@; \\', file = filehandle)
    print('\telse \\', file = filehandle)
    print('\t  rm -f ', data.outputs[subphase][division][0], "; \\", sep = '', file = filehandle)
    print('\t  $(MAKE) --no-print-directory -f $(PWD)/', filename, ' ', data.outputs[subphase][division][0], '; \\', sep = '', file = filehandle)
    print('\tfi', file = filehandle)
    print(file = filehandle)

  # Write the final instructions to the makefile.
  def completeFile(self, filehandle, outputs):

    # Prior to closing the file, include instructions for generating an 'ok' file indicating that the
    # makefile was successfully executed and delete the makefile.
    print('### Generate a file indicating successful execution of makefile', file = filehandle)
    print('$(COMPLETE_OK): ', end = '', file = filehandle)

    # Add all of the outputs generated by this makefile to the list of dependencies. The 'ok' file is
    # only created if the pipeline ran successfully and generated everything required.
    for filename in outputs: print(filename, end = ' ', file = filehandle)
    print(file = filehandle)
    print('\t@rm -f $(MAKEFILE_ID).make', file = filehandle)
    print('\t@touch $(COMPLETE_OK)', file = filehandle)

#  # Add the command lines to the makefiles.
#  def addCommandLines(self, graph, struct):
#
#    # Loop over the phases, subphases and divisions. By looping over the makefiles in reverse order, any files
#    # marked as intermediate can be deleted as soon as they are seen, as this will be the last task in the
#    # pipeline in which they are used.
#    for phase in self.makefileNames.keys():
#      i = 0
#      for subphase in self.makefileNames[phase].keys():
#        for division in self.makefileNames[phase][subphase].keys():
#
#          # Get the makefile name and filehandle.
#          makefileName = self.makefileNames[phase][subphase][division]
#          filehandle   = self.makefilehandles[phase][subphase][division]
#
#          # Loop over the tasks for this makefile adding the command lines.
#          for task in struct.phaseInformation[phase].tasks:
#            isInputStream  = graph.getGraphNodeAttribute(task, 'isInputStream')
#            isOutputStream = graph.getGraphNodeAttribute(task, 'isOutputStream')
#
#            # If this task outputs to a stream, no information should be written to the makefiles at this point.
#            # All of the tasks that are part of the stream should be processed, so that the list of dependencies
#            # and outputs can be constructed properly. If the task does not accept an input stream, then this is
#            # the first task in the set of piped tools, so a data structure should be initialised.
#            if isOutputStream:
#              if not isInputStream: info = streamingInformation()
#              self.storeStreamingTaskInformation(info, task, i, isLast = False)
#
#            # If this task accepts an input stream and isn't outputting to a stream, all of the stored information
#            # as well as the information for this task can be written to file.
#            elif isInputStream:
#              self.storeStreamingTaskInformation(info, task, i, isLast = True)
#              self.writeStreamingInformation(graph, info, i, filehandle)
#
#            # If this does not accept a stream or output to a stream, just write the information to the makefile.
#            else: self.writeStandardInformation(graph, task, i, makefileName, filehandle)
#
#          # Increment the counter.
#          i += 1

  # Generate the makefiles for this execution of gkno.
#  def generateMakefiles(self, struct, pipeline, gknoArguments, arguments):
#
#    # Check if multiple makefiles were requested.
#    mm = gknoArguments['GKNO-MULTIPLE-MAKEFILES'].longFormArgument
#    self.isMultipleMakefiles = True if mm in arguments else False
#
#    # Check if a makefile ID was supplied.
#    mid = gknoArguments['GKNO-MAKEFILE-ID'].longFormArgument
#    if mid in arguments: self.makefileID = arguments[mid][0]
#
#    # Define the baseName for the makefiles.
#    baseName = str(pipeline + '-' + self.makefileID) if self.makefileID else str(pipeline)
#
#    # Loop over all the phases and set the names of all of the makefiles. Also link each
#    # phase/subphase/division to the makefile.
#    if self.isMultipleMakefiles:
#      for phase in struct.phaseInformation:
#  
#        # Add the phase to the makefile name (if there are multiple phases).
#        if phase not in self.makefileNames: self.makefileNames[phase] = {}
#        if len(struct.phaseInformation.keys()) == 1: phaseName = baseName
#        else: phaseName = str(baseName + '-phase' + str(phase))
#  
#        for subphase in range(1, struct.phaseInformation[phase].numberSubphases + 1):
#  
#          # Add the subphase to the makefile name (if there are multiple subphases).
#          if subphase not in self.makefileNames[phase]: self.makefileNames[phase][subphase] = {}
#          if struct.phaseInformation[phase].numberSubphases == 1: name = phaseName
#          else: name = str(phaseName + '-subphase' + str(subphase))
#
#          # Add a set of random characters to the makefile name. After execution the makefile will be deleted, but
#          # by appending random characters, if gkno is run multiple times, any existing makefiles will not be
#          # overwritten.
#          name += str('-' + stringOps.getRandomString(8))
#  
#          # Add the makefile names.
#          if struct.phaseInformation[phase].numberDivisions == 1: self.makefileNames[phase][subphase][1] = str(name + '.make')
#          else:
#            for division in range(1, struct.phaseInformation[phase].numberDivisions + 1):
#              self.makefileNames[phase][subphase][division] = str(name + '-division' + str(division) + '.make')
#
#    # If only a single makefile is being produced, everything links to the same makefile.
#    else:
#      for phase in struct.phaseInformation:
#        if phase not in self.makefileNames: self.makefileNames[phase] = {}
#        for subphase in range(1, struct.phaseInformation[phase].numberSubphases + 1):
#          if subphase not in self.makefileNames[phase]: self.makefileNames[phase][subphase] = {}
#
#          # Add random characters to the makefile name (see above).
#          baseName += str('.' + stringOps.getRandomString(8))
#          if struct.phaseInformation[phase].numberDivisions == 1: self.makefileNames[phase][subphase][1] = str(baseName + '.make')
#          else:
#            for division in range(1, struct.phaseInformation[phase].numberDivisions + 1):
#              self.makefileNames[phase][subphase][division] = str(baseName + '.make')

#  # Get the makefile name for a given phase, subphase and division.
#  def getMakefileName(self, phase, subphase, division):
#    return self.makefileNames[phase][subphase][division]

  # Open all of the required makefiles.
#  def openFiles(self, graph, struct, commitID, date, version, pipeline, sourcePath, toolPath, resourcePath):
#
#    # If there are not multiple makefiles being made, then there is no need to loop over all the
#    # phases etc, as all phases point to the same makefile. In this event, just open the single
#    # makefile.
#    if not self.isMultipleMakefiles: self.singleFileHeader(graph, struct, commitID, date, version, pipeline, sourcePath, toolPath, resourcePath)
#    else: self.multifileHeader(graph, struct, commitID, date, version, pipeline, sourcePath, toolPath, resourcePath)

#  # Write the header text to a single makefile.
#  def singleFileHeader(self, graph, struct, commitID, date, version, pipeline, sourcePath, toolPath, resourcePath):
#
#    # Define the filehandle.
#    filename   = self.makefileNames[1][1][1]
#    filehandle = fh.fileHandling.openFileForWriting(filename)
#
#    # Add header text to the file.
#    self.addHeader(graph, struct, filehandle, commitID, date, version, pipeline, sourcePath, toolPath, resourcePath, self.makefileNames[1][1][1], 1)
#
#    # Loop over all the phases, subphases and divisions.
#    allIntermediates = []
#    allOutputs       = []
#    tempOutputs      = []
#    for phase in self.makefileNames:
#      subphases = struct.phaseInformation[phase].numberSubphases
#      divisions = struct.phaseInformation[phase].numberDivisions
#      for task in struct.phaseInformation[phase].tasks:
#        for subphase in range(1, subphases + 1):
#          for division in range(1, divisions + 1):
#            allOutputs.extend(self.executionInfo[task].outputs[subphase][division])
#            allIntermediates.extend(self.executionInfo[task].intermediates[subphase][division])
#
#    # Remove duplicates from the lists.
#    allIntermediates = list(set(allIntermediates))
#    allOutputs       = list(set(allOutputs))
#
#    # Remove output files that are also marked as intermediates.
#    allOutputs = list(set(allOutputs) - set(allIntermediates))
#
#    # Add the intermediate and output files.
#    self.addIntermediateFiles(allIntermediates, filename, filehandle)
#    self.addOutputFiles(allOutputs, filehandle)
#
#    # Remove the file created on successful execution of the makefile.
#    self.removeOk(filehandle)
#
#    # Return the list of outputs generated by this makefile.
#    return allOutputs
#
#  # Write header text to multiple makefiles.
#  def multifileHeader(self, graph, struct, commitID, date, version, pipeline, sourcePath, toolPath, resourcePath):
#    print('NOT HANDLED MULTIPLE MAKEFILES'); exit(0)

#    # Loop over all the phases, subphases and divisions.
#    for phase in self.makefileNames:
#      i = 0
#
#      # Initialise arrays.
#      if phase not in self.makefilehandles:
#        self.makefilehandles[phase] = {}
#        self.makefileOutputs[phase] = {}
#
#      for subphase in self.makefileNames[phase]:
#
#        # Initialise arrays.
#        if subphase not in self.makefilehandles[phase]:
#          self.makefilehandles[phase][subphase] = {}
#          self.makefileOutputs[phase][subphase] = {}
#
#        for division in self.makefileNames[phase][subphase]:
#
#          # Create a new filehandle and add the header text.
#          filename   = self.makefileNames[phase][subphase][division]
#          filehandle = fh.fileHandling.openFileForWriting(filename)
#
#          # Add the header, intermediate files and all output files for the phase.
#          self.addHeader(graph, struct, filehandle, commitID, date, version, pipeline, sourcePath, toolPath, resourcePath, filename, phase)
#          tempIntermediates = self.getFiles(struct, phase, 'intermediates', i)
#          tempOutputs       = self.getFiles(struct, phase, 'outputs', i)
#
#          # If this is the final task in the makefile, all output files should be included as outputs, not
#          # intermediates, even if so marked. If this is not followed, there could be phases that produce
#          # no output files, which would ensure that the makefile would not execute.
#          finalOutputs = self.getFinalTaskOutputs(struct, phase, i)
#
#          # Remove final outputs from the intermediates.
#          intermediates = []
#          for intermediate in tempIntermediates:
#            if intermediate not in finalOutputs: intermediates.append(intermediate)
#
#          # Remove intermediate files from the outputs.
#          outputs = []
#          for output in tempOutputs:
#            if output not in intermediates: outputs.append(output)
#
#          # Add the intermediate and output files.
#          self.addIntermediateFiles(intermediates, filename, filehandle)
#          self.addOutputFiles(outputs, filehandle)
#
#          # Remove the file created on successful execution of the makefile.
#          self.removeOk(filehandle)
#
#          # Add the makefile handle to the data structure.
#          self.makefilehandles[phase][subphase][division] = filehandle
#
#          # Store the list of output files generated by this makefile.
#          self.makefileOutputs[phase][subphase][division] = finalOutputs
#
#          # Increment the counter.
#          i += 1
#
#  # Get files for the task and phase.
#  def getFiles(self, struct, phase, fileType, i):
#    files = []
#
#    # Loop over the tasks for this phase.
#    for task in struct.phaseInformation[phase].tasks:
#
#      # Define the files to loop over.
#      print('\t', task,fileType, self.executionInfo[task].intermediates)
#      if fileType == 'intermediates': fileList = self.executionInfo[task].intermediates
#      elif fileType == 'outputs': fileList = self.executionInfo[task].outputs
#
#      # Get the files. If there are multiple makefiles, only take the values from the current phase, subphase
#      # and division.
#      for value in fileList[i]:
#        if value not in files: files.append(value)
#
#    # Return the files.
#    return files
#
#  # Return the output files from the final task in this phase.
#  def getFinalTaskOutputs(self, struct, phase, i):
#    files = []
#
#    # Get the files.
#    for value in self.executionInfo[struct.phaseInformation[phase].tasks[-1]].outputs[i]:
#      if value not in files: files.append(value)
#
#    # Return the files.
#    return files


#  # Close all the open makefiles.
#  def closeFiles(self):
#
#    # If only a single makefile was created, only a single file needs to be closed.
#    if not self.isMultipleMakefiles:
#      filehandle = self.makefilehandles[1][1][1]
#      filename   = self.makefileNames[1][1][1]
#      self.completeFile(filename, filehandle)
#
#      # Close the file.
#      fh.fileHandling.closeFile(filehandle)
#
#    # If multiple files were opened, close them all.
#    else:
#      for phase in self.makefilehandles:
#        for subphase in self.makefilehandles[phase]:
#          for division in self.makefilehandles[phase][subphase]:
#            filehandle = self.makefilehandles[phase][subphase][division]
#            filename   = self.makefileNames[1][1][1]
#            self.completeFile(filename, filehandle)
#
#            # Close the file.
#            fh.fileHandling.closeFile(filehandle)

  # Return the argument to be written to the command line (and consequently, that stored in the commands
  # data structure). It is usually the case that the gkno argument does not correspond to the tool
  # argument.
  def getToolArgument(self, graph, task, nodeId, isInput):
    inputInstructions  = graph.getArgumentAttribute(nodeId, task, 'inputStreamInstructions')
    outputInstructions = graph.getArgumentAttribute(task, nodeId, 'outputStreamInstructions')

    # Determine streaming instructions, beginning with if this is an input accepting a stream.
    if graph.getGraphNodeAttribute(task, 'isInputStream') and inputInstructions:

      # If the argument should be omitted.
      if inputInstructions['argument'] == 'omit': return None
 
      # Return the supplied value to use as the argument.
      else: return str(inputInstructions['argument'])

    # Now handle outputting to a stream.
    elif graph.getGraphNodeAttribute(task, 'isOutputStream') and outputInstructions:
  
      # Check for the different allowed modifications to the argument. If the argument is listed as omit,
      # the argument should be omitted from the command line (not replaced with another value). In this
      # case, return None.
      if outputInstructions['argument'] == 'omit': return None
  
      # If the instructions are none of the above, the argument should be replaced with the supplied value.
      # In this case, return the value supplied.
      else: return str(outputInstructions['argument'])

    # Otherwise, use the other instructions.
    else:
  
      # If the argument is for an input file.
      if isInput:
        commandLineArgument = graph.getArgumentAttribute(nodeId, task, 'commandLineArgument')
        modifyArgument      = graph.getArgumentAttribute(nodeId, task, 'modifyArgument')
  
      # And if the argument is for an output file.
      else: 
        commandLineArgument = graph.getArgumentAttribute(task, nodeId, 'commandLineArgument')
        modifyArgument      = graph.getArgumentAttribute(task, nodeId, 'modifyArgument')
  
      # Return the argument to be used on the command line.
      if modifyArgument == 'omit': return None

      # If the output should be redirected to stdout, there should be no command, just the redirection.
      elif modifyArgument == 'stdout': return '>>'
      else: return commandLineArgument

  #######################################################
  ### Static methods for getting makefile information ###
  #######################################################

  # If the input/output is a stream, determine how the value should be written to the command line.
  @staticmethod
  def getStreamValue(graph, source, target, value, isInput, isStub):
    if isInput: instructions = graph.getArgumentAttribute(source, target, 'inputStreamInstructions')
    else: instructions = graph.getArgumentAttribute(source, target, 'outputStreamInstructions')

    # Return the value based on the instructions.
    if instructions['value'] == 'omit': return None

    # If none of the above instructions are set, return the value supplied in the instructions. This is
    # what will be used in place of the value.
    else: return str(instructions['value'])

  # Similar method to the getToolArgument except for the associated value.
  @staticmethod
  def getValue(graph, source, target, value, isInput, isStub, stubExtension):

    # If the argument is for an input file.
    modifyValue = graph.getArgumentAttribute(source, target, 'modifyValue')

    # Check if the value should be included in quotation marks.
    inQuotations = graph.getArgumentAttribute(source, target, 'includeInQuotations')

    # If this is a stub, add the extension to the value and return.
    if isStub:
      if not graph.getArgumentAttribute(source, target, 'primaryStubNode'): return None
      else: 
        try: updatedValue = value.rstrip(stubExtension)
        except: updatedValue = value
        updatedValue = updatedValue.rstrip('.') if updatedValue.endswith('.') else updatedValue
        if inQuotations: return str('"' + updatedValue + '"')
        else: return updatedValue

    # If this is not a stub, return the argument to be used on the command line.
    if modifyValue == 'omit': return None

    # Include the value in quotations, if requested.
    elif inQuotations: return str('"' + value + '"')

    # Otherwise, just return the original value.
    else: return value

  # Build a line of the command line.
  @staticmethod
  def buildLine(argument, delimiter, value):

    # If neither the argument or the value are populated, return None.
    if not argument and not value: return None

    # If the value is defined, but the argument is not, this is a tool that does not use arguments on the
    # command line and so the command should be the value only.
    elif not argument: return '\t' + str(value) + ' \\'

    # If only the argument is defined, this is a flag, so only the argument is returned.
    elif not value: return '\t' + str(argument) + ' \\'

    # Finally, if both are defined, return the correctly delimited argument, value pair.
    else: return '\t' + str(argument) + str(delimiter) + str(value) + ' \\'
    line = '\t' + str(argument) + str(delimiter) + str(value) + ' \\'

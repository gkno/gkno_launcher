#!/bin/bash/python

from __future__ import print_function
from copy import deepcopy
import collections

import fileHandling as fh
import makefileErrors
import stringOperations as stringOps

import json
import os
import sys

# Define a class to hold information about the command line.
class commandLineInformation():
  def __init__(self, graph, superpipeline, struct, task):

    # Store the task and tool.
    self.task     = task
    self.tool     = graph.getGraphNodeAttribute(task, 'tool')
    self.toolData = superpipeline.toolConfigurationData[self.tool]

    # Store if the task is greedy or consolidates divisions.
    self.isGreedy      = graph.getGraphNodeAttribute(task, 'isGreedy')
    self.isConsolidate = graph.getGraphNodeAttribute(task, 'isConsolidate')

    # Determine the number of command lines to be created for the task. This can be determined by finding
    # the phase in which the task resides in the pipeline execution structure, and then determining the
    # number of subphases and divisions within the phase. The total number of command lines is equal to the
    # product of these two values.
    self.phase              = struct.task[task]
    self.numberSubphases    = struct.phaseInformation[self.phase].numberSubphases
    self.numberDivisions    = struct.phaseInformation[self.phase].numberDivisions
    self.numberCommandLines = self.numberSubphases * self.numberDivisions

    # Get the executable information.
    self.executable = self.toolData.executable
    self.modifier   = self.toolData.modifier
    self.path       = self.toolData.path
    self.precommand = self.toolData.precommand

    # Get the argument delimiter for this tool.
    self.delimiter = self.toolData.delimiter

    # Define and store the path to the executable.
    self.toolID = str(self.tool.upper() + '-PATH')

    # Store the command lines for this task. This is indexed by the subphase and the division. Store
    # the dependencies, intermediates, output files and files for standard out to write to, for each
    # command line with the same structure.
    self.commands      = {}
    self.dependencies  = {}
    self.intermediates = {}
    self.outputs       = {}
    self.stdouts       = {}
    for i in range(1, self.numberSubphases + 1):
      self.commands[i]      = {}
      self.dependencies[i]  = {}
      self.intermediates[i] = {}
      self.outputs[i]       = {}
      self.stdouts[i]       = {}
      for j in range(1, self.numberDivisions + 1):
        self.commands[i][j]      = []
        self.dependencies[i][j]  = []
        self.intermediates[i][j] = []
        self.outputs[i][j]       = []
        self.stdouts[i][j]       = str('\t>> $(STDOUT) \\')

# Define a class that is a data structure for holding information for tasks that are piped
# together.
class streamingInformation:
  def __init__(self):
    self.commands       = []
    self.dependencies   = []
    self.intermediates  = []
    self.outputs        = []
    self.streamedFiles  = []
    self.tasks          = []

# Define a class to build and manipulate makefiles.
class makefiles:
  def __init__(self):

    # Handle errors associated with makefile construction.
    self.errors = makefileErrors.makefileErrors()

    # Store the paths of all the tools executed in the pipeline.
    self.toolPaths = {}

    # Store information including command lines, dependencies and outputs for each task.
    self.executionInfo = {}

    # Record if multiple makefiles are to be generated.
    self.isMultipleMakefiles = False

    # Store the user specified ID to add to all makefile filesnames.
    self.makefileId = None

    # Store the makefile names and file handles.
    self.filehandles   = {}
    self.filenames     = {}
    self.filenamesList = []
    self.keys          = {}

    # Store the name of the makefile and the filehandle if there is only a single file.
    self.singleFilename   = None
    self.singleFilehandle = None

    # Store the outputs generated by each makefile.
    self.makefileOutputs = {}

  # Generate the command lines associated with a task.
  def generateCommandLines(self, graph, superpipeline, struct):

    # Loop over all the tasks in the pipeline, generating the command lines for each task.
    for task in graph.workflow:

      # Get the tool used to run the task and the data contained in the configuration file.
      tool     = graph.getGraphNodeAttribute(task, 'tool')
      toolData = superpipeline.toolConfigurationData[tool]

      # Determine whether the input or the output from this task are streams.
      isInputStream  = graph.getGraphNodeAttribute(task, 'isInputStream')
      isOutputStream = graph.getGraphNodeAttribute(task, 'isOutputStream')

      # Loop over all of the nodes and get the arguments that are going to be used and the
      # node IDs to which they connect. This will then be used to allow the arguments to 
      # be parsed in the order specified.
      inputArguments  = self.getArguments(graph, task, graph.getInputFileNodes(task), isInput = True)
      optionArguments = self.getArguments(graph, task, graph.getOptionNodes(task), isInput = True)
      outputArguments = self.getArguments(graph, task, graph.getOutputFileNodes(task), isInput = False)

      # Check if the tool arguments need to be included in a defined order.
      argumentOrder = toolData.argumentOrder
      if not argumentOrder: argumentOrder = inputArguments.keys() + optionArguments.keys() + outputArguments.keys()

      # Generate a data structure for building the command line.
      data = commandLineInformation(graph, superpipeline, struct, task)
  
      # Store the tools path in the global makefiles dictionary toolPaths. If the path is listed
      # as 'none', do not include the path.
      if data.tool not in self.toolPaths and data.path != 'none': self.toolPaths[data.tool] = str(data.toolID + '=$(TOOL_BIN)/' + data.path)
  
      # The output of the method is a list of command lines, one command line for each execution
      # of the task. Each command line is itself a list of the command line executable and arguments.
      # First determine the command line executable.
      path = ' ' if data.path == 'none' else ' $(' + data.toolID + ')/'
      command = str(data.precommand + path + data.executable + ' ' + data.modifier).rstrip(' ').strip(' ')
  
      # Add the executable to the command lines and initialise the lists of dependencies and outputs
      # to have the same length as the commands.
      for i in range(1, data.numberSubphases + 1):
        for j in range(1, data.numberDivisions + 1):
          if not isInputStream: data.commands[i][j].append('\t@' + command + ' \\')
          else: data.commands[i][j].append('\t' + command + ' \\')

      # Loop over the argument order for the tool, getting information from the nodes in the correct
      # order. The argument order is populated with the arguments in random order if the order wasn't
      # specified in the configuration file.
      for argument in argumentOrder:
        if argument in optionArguments:
          for nodeId in optionArguments[argument]: self.addOption(graph, task, data, nodeId)
        if argument in inputArguments:
          for nodeId in inputArguments[argument]: self.addInput(graph, task, data, nodeId)
        if argument in outputArguments:
          for nodeId in outputArguments[argument]: self.addOutput(graph, task, data, nodeId)

      # Finish the command lines with calls to write to stdout and stdin and indicating that the task is complete.
      # These values are modified based on whether the task is outputting to a stream or not.
      for i in range(1, data.numberSubphases + 1):
        for j in range(1, data.numberDivisions + 1):
          if isOutputStream:
            data.commands[i][j].append('\t2>> $(STDERR) \\')
            data.commands[i][j].append('\t| \\')
  
          else:
            data.commands[i][j].append(data.stdouts[i][j])
            data.commands[i][j].append('\t2>> $(STDERR)')
            data.commands[i][j].append('\t@echo -e "completed successfully."')
            data.commands[i][j].append('\t@touch $(EXECUTED)')
            data.commands[i][j].append('')

      # Store the command lines for the task.
      self.executionInfo[task] = data

  # Find all the arguments for a task.
  def getArguments(self, graph, task, nodeIds, isInput):
    arguments = {}
    for nodeId in nodeIds:

      # If the node is a child, ignore it. In order to ensure that filenames will appear in the correct order of divisions,
      # the parent node must appear first in the list, followed by the children in division order.
      if not graph.getGraphNodeAttribute(nodeId, 'isChild'):
        if isInput: argument = graph.getArgumentAttribute(nodeId, task, 'longFormArgument')
        else: argument = graph.getArgumentAttribute(task, nodeId, 'longFormArgument')
  
        if argument in arguments: arguments[argument].append(nodeId)
        else: arguments[argument] = [nodeId]

        # If this is an input and a parent node, add the children to the list in the correct order.
        if isInput and graph.getGraphNodeAttribute(nodeId, 'isParent'):
          for child in graph.getGraphNodeAttribute(nodeId, 'children'): arguments[argument].append(child)

    # Return the arguments.
    return arguments

  # Add option values to the command lines.
  def addOption(self, graph, task, data, nodeId):

    # Get the argument, values and data type for the option node.
    argument = self.getToolArgument(graph, task, nodeId, isInput = True)
    values   = graph.getGraphNodeAttribute(nodeId, 'values')
    dataType = graph.getArgumentAttribute(nodeId, task, 'dataType')

    # Determine if this option can be specified multiple times on the command line, or if this
    # option is used to create divisions..
    isAllowMultipleValues = graph.getArgumentAttribute(nodeId, task, 'allowMultipleValues')
    isCreateDivision      = graph.getGraphNodeAttribute(nodeId, 'isCreateDivision')

    # If the argument is a flag, it cannot be given multiple values.
    if dataType == 'flag' and len(values) > 1: print('ERROR - makefiles.addOption - 3'); exit(1)

    # Regardless of the number of values supplied, each subphase needs to receive the same values.
    # Any differences between command lines would occur for multiple divisions. So, loop over all
    # divisions and apply the same command line to each subphase within the division.
    for i in range(1, data.numberDivisions + 1):
      lines = []

      # If the option creates the divisions, create the line based on the ith value. 
      if isCreateDivision and not isAllowMultipleValues:
        #TODO ERROR
        if len(values) != data.numberDivisions: print('ERROR - makefiles.addOption - 1', task, nodeId); exit(1)
        lineValue = self.getValue(graph, nodeId, task, values[i - 1], isInput = True, isStub = False, stubExtension = None)
        lines.append(self.buildLine(argument, data.delimiter, lineValue))

      # If this option does not create the divisions, but there are multiple values, they must all be applied on the
      # same command line. Again, this cannot be a flag.
      elif len(values) > 1:

        # Check that the option is permitted to be applied multiple times.
        if not isAllowMultipleValues: print('ERROR - makefiles.addOption - 2', argument, len(values)); exit(1)
        for value in values:
          lineValue = self.getValue(graph, nodeId, task, value, isInput = True, isStub = False, stubExtension = None)
          lines.append(self.buildLine(argument, data.delimiter, lineValue))

      # If there is only a single value, build the line considering if this is a flag.
      else:

        # If the option is a flag, there is no value to output, so set this to a blank.
        if dataType == 'flag':
          lineValue = ''
          if values[0] != 'set': argument = ''

        # If the value is set, the flag should be set on the command line, otherwise, this should be left blank.
        else: lineValue = self.getValue(graph, nodeId, task, values[0], isInput = True, isStub = False, stubExtension = None)

        # Only add the line to the lines if the flag is set.
        line = self.buildLine(argument, data.delimiter, lineValue)
        if line: lines.append(line)

      # Add the options to the command lines for each subphase.
      for j in range(1, data.numberSubphases + 1): data.commands[j][i].extend(lines)

  # Add input files to the command line.
  def addInput(self, graph, task, data, nodeId):

    # Get the argument, values and data type for the option node.
    argument = self.getToolArgument(graph, task, nodeId, isInput = True)
    values   = graph.getGraphNodeAttribute(nodeId, 'values')
    dataType = graph.getArgumentAttribute(nodeId, task, 'dataType')

    # Determine if this option can be specified multiple times on the command line and if the task is listed
    # as being greedy.
    isAllowMultipleValues = graph.getArgumentAttribute(nodeId, task, 'allowMultipleValues')
    isGreedy              = graph.getGraphNodeAttribute(task, 'isGreedy')

    # Check if this node contains intermediate files.
    #isIntermediate = graph.getGraphNodeAttribute(nodeId, 'isIntermediate')
    isIntermediate = True if graph.getGraphNodeAttribute(nodeId, 'deleteAfterTask') == task else False

    # Determine if this is a stub.
    isStub        = graph.getArgumentAttribute(nodeId, task, 'isStub')
    stubExtension = graph.getArgumentAttribute(nodeId, task, 'stubExtension')

    # Determine if this argument is for a stream.
    isStream = graph.getArgumentAttribute(nodeId, task, 'isStream')

    # Convert the values into the form required on the command line.
    if isStream: lineValues = [self.getStreamValue(graph, nodeId, task, value, True, isStub) for value in values]
    else: lineValues = [self.getValue(graph, nodeId, task, value, True, isStub, stubExtension) for value in values]

    # If this task is greedy, check that the argument allows multiple values to be set and that there is only a single
    # subphase. Then create the command line.
    if isGreedy:
      #TODO ERROR
      if len(values) > 1:
        if not isAllowMultipleValues: print('ERROR - makefiles.addInput - 1'); exit(1)
        if data.numberSubphases > 1: print('ERROR - makefiles.addInput - 2'); exit(1)

    # Regardless of the number of values supplied, each division needs to receive the same values.
    # Each subphase operates on either all the input files, or a subset, but if there are divisions,
    # each division has the same input files. The differences in the divisions come from different
    # supplied options.
    for subphase in range(1, data.numberSubphases + 1):
      lines = []

      # If this task is greedy, check that the argument allows multiple values to be set and that there is only a single
      # subphase. Then create the command line.
      if isGreedy or len(lineValues) == 1:

        # Loop over the values and add to the command line.
        for value in lineValues:
          lineValue = self.getValue(graph, nodeId, task, value, isInput = True, isStub = isStub, stubExtension = stubExtension)
          line      = self.buildLine(argument, data.delimiter, lineValue)
          if line: lines.append(line)

      # If the task isn't greedy and has multiple values, each value is used for a seperate subphase.
      elif len(lineValues) > 1:
        lineValue = self.getValue(graph, nodeId, task, lineValues[subphase - 1], isInput = True, isStub = isStub, stubExtension = stubExtension)
        line      = self.buildLine(argument, data.delimiter, lineValue)
        if line: lines.append(line)

      # Add the options to the command lines for each subphase.
      for division in range(1, data.numberDivisions + 1):
        data.commands[subphase][division].extend(lines)

        # Add the files to the dependencies or outputs for the command line (if not being streamed).
        if not isStream:
          if isGreedy and len(lineValues) > 1:
            for value in values: data.dependencies[subphase][division].append(str(value))
          elif len(values) > 1: data.dependencies[subphase][division].append(str(values[subphase - 1]))
          else: data.dependencies[subphase][division].append(str(values[0]))
    
          # Add to the intermediates if necessary.
          if isIntermediate:
            if isGreedy and len(values) > 1:
              for value in values:
                if str(value) not in data.intermediates[subphase][division]: data.intermediates[subphase][division].append(str(value))
            elif len(values) > 1:
              if str(values[subphase - 1]) not in data.intermediates[subphase][division]: data.intermediates[subphase][division].append(str(values[subphase - 1]))
            else:
              if str(values[0]) not in data.intermediates[subphase][division]: data.intermediates[subphase][division].append(str(values[0]))

  # Add input files to the command line.
  def addOutput(self, graph, task, data, nodeId):

    # Get the argument, values and data type for the option node.
    argument = self.getToolArgument(graph, task, nodeId, isInput = False)
    values   = graph.getGraphNodeAttribute(nodeId, 'values')
    dataType = graph.getArgumentAttribute(task, nodeId, 'dataType')

    # Check if this task has children. If so, the outputs for the different subphases will be attached to the child nodes.
    isParent = graph.getGraphNodeAttribute(nodeId, 'isParent')
    children = graph.getGraphNodeAttribute(nodeId, 'children')

    # Check if this node contains intermediate files.
    #isIntermediate = graph.getGraphNodeAttribute(nodeId, 'isIntermediate')
    isIntermediate = True if graph.getGraphNodeAttribute(nodeId, 'deleteAfterTask') == task else False

    # Determine if this is a stub.
    isStub         = graph.getArgumentAttribute(task, nodeId, 'isStub')
    stubExtension  = graph.getArgumentAttribute(task, nodeId, 'stubExtension')
    includeStubDot = graph.getArgumentAttribute(task, nodeId, 'includeStubDot')
    isPrimaryNode  = graph.getArgumentAttribute(task, nodeId, 'primaryStubNode')

    # Determine if this argument is for a stream.
    isStream = graph.getArgumentAttribute(task, nodeId, 'isStream')

    # Convert the values into the form required on the command line.
    if isStream: lineValues = [self.getStreamValue(graph, task, nodeId, value, False, isStub) for value in values]
    else: lineValues = [self.getValue(graph, task, nodeId, value, False, isStub, stubExtension) for value in values]

    # If this is a parent node, then the task has been split into divisions. The parent file node and it's children each
    # correspond to a division. Thus the values contained in them are for each subphase with the division. Begin by looping
    # over the values in the parent node. This corresponds to the first division, then each value is for each of the
    # subphases. Then loop over the children and populate the subphase outputs for each division.
    #
    # Deal with the first division. If there are multiple divisions, this is the values from the parent node. If there is
    # only a single division, this is the only node that exists.
    for subphase, value in enumerate(values):
      lineValue = lineValues[subphase]
      if isStub and not isPrimaryNode: line = None
      else: line = self.buildLine(argument, data.delimiter, lineValue)
      if line:

        # If this task outputs to stdout, update the stdouts data structure,
        if line.startswith('\t>>'): data.stdouts[subphase + 1][1] = str(line)
        else: data.commands[subphase + 1][1].append(line)

      # Add the files to the dependencies or outputs for the command line (do not add the values to the list of
      # inputs and dependencies if the files are being streamed).
      if not isStream:
        data.outputs[subphase + 1][1].append(str(value))

        # If this is an intermediate file, add to the list of intermediate files.
        if isIntermediate and str(value) not in data.intermediates[subphase + 1][1]: data.intermediates[subphase + 1][1].append(str(value))

    # If there are multiple divisions, values for division 2 onwards are stored in the child nodes which are dealt with here.
    if isParent:
      for child in children:
        division = graph.getGraphNodeAttribute(child, 'divisionID') + 1
        lines    = []

        # Convert the values into the form required on the command line.
        values = graph.getGraphNodeAttribute(child, 'values')
        if isStream: lineValues = [self.getStreamValue(graph, task, nodeId, value, False, isStub) for value in values]
        else: lineValues = [self.getValue(graph, task, nodeId, value, False, isStub, stubExtension) for value in values]

        for subphase, value in enumerate(values):
          lineValue = lineValues[subphase]
          if isStub and not isPrimaryNode: line = None
          else: line = self.buildLine(argument, data.delimiter, lineValue)
          if line: data.commands[subphase + 1][division].append(line)

          # Add the files to the dependencies or outputs for the command line (do not add the values to the list of
          # inputs and dependencies if the files are being streamed).
          if not isStream:
            data.outputs[subphase + 1][division].append(str(value))
    
            # If this is an intermediate file, add to the list of intermediate files.
            if isIntermediate and str(value) not in data.intermediates[subphase + 1][division]: data.intermediates[subphase + 1][division].append(str(value))

  # Check if the value has the given extension and, if not, add it.
  def addStubExtension(self, value, extension, includeStubDot):
    if value.endswith(extension): return value
    else:
      updatedValue = str(value + '.' + extension) if includeStubDot else str(value + extension)
      return updatedValue

  # If a single makefile is being generated, set the name and open the file.
  def openSingleMakefile(self, pipeline):
    filename = str(pipeline + '-' + self.makefileId) if self.makefileId else str(pipeline)

    # Add a random string to the makefile name. This ensures that if gkno has been executed in a loop,
    # multiple runs of gkno in the same directory for the same pipeline will create makefiles with
    # unique names.
    filename += str('.' + stringOps.getRandomString(8) + '.make')

    # Open the file for writing.
    filehandle = fh.fileHandling.openFileForWriting(ilename)

  # Generate all of the makefile names if multiple makefiles are being generated and open them all for writing.
  def openMakefiles(self, pipeline, struct):

    # Define the base makefile name.
    basename = str(pipeline + '-' + self.makefileId) if self.makefileId else str(pipeline)

    for phase in struct.phaseInformation:
      divisions = struct.phaseInformation[phase].numberDivisions
      subphases = struct.phaseInformation[phase].numberSubphases

      # If there are multiple phases, add the phase to the filename.
      phaseFilename = basename + str('.phase' + str(phase)) if len(struct.phaseInformation) > 1 else basename

      # Loop over all subphases and divisions.
      for subphase in range(1, subphases + 1):
        for division in range(1, divisions + 1):

          # Generate the filenames if multiple makefiles are being produced.
          if self.isMultipleMakefiles:
            filename = phaseFilename
  
            # If the phase has multiple phases and/or divisions, add these to the filename.
            if subphases > 1: filename += str('.subphase' + str(subphase))
            if divisions > 1: filename += str('.division' + str(division))
 
          # If there is only a single makefile, the name is simply the base name.
          else: filename = basename

          # Add a random string to the makefile name. This ensures that if gkno has been executed in a loop,
          # multiple runs of gkno in the same directory for the same pipeline will create makefiles with
          # unique names.
          filename += str('.' + stringOps.getRandomString(8) + '.make')

          # Open the file for writing. If this is a single makefile, this should only happen once.
          if self.isMultipleMakefiles or (phase + subphase + division) == 3:
            filehandle = fh.fileHandling.openFileForWriting(filename)
            self.filenamesList.append(filename)

          # Store the filenames and filehandles in a dictionary, keyed by the ordered combination of the phase,
          # subphase and division..
          key                        = str(phase) + str(subphase) + str(division)
          self.filenames[key]        = filename
          self.filehandles[filename] = filehandle
          self.keys[filename]        = key

    # If there is only a single makefile, store its name and filehandle.
    if not self.isMultipleMakefiles:
      self.singleFilename   = self.filenamesList[0]
      self.singleFilehandle = self.filehandles[self.singleFilename]

  # Add header text to the file.
  def addHeader(self, commitID, date, version, pipeline, sourcePath, toolsPath, resourcesPath):

    # Loop over all makefiles.
    for filename in self.filenamesList:
      filehandle = self.filehandles[filename]

      # Add basic text about the gkno version.
      print('### gkno makefile', file = filehandle)
      print('### Generated using gkno version: ', version, ' (', date, ')', sep = '', file = filehandle)
      print('### gkno commit: ', commitID, sep = '', file = filehandle)
      print('### Pipeline: ', pipeline, sep = '', file = filehandle)
      print(file = filehandle)
      print('### Set the shell to bash.', file = filehandle)
      print('SHELL=/bin/bash', file = filehandle)
      print(file = filehandle)
  
      # Include the paths to tools and resources.
      print('### Paths to tools and resources.', file = filehandle)
      print('GKNO_PATH=', sourcePath, sep = '', file = filehandle)
      print('TOOL_BIN=', toolsPath, sep = '', file = filehandle)
      print('RESOURCES=', resourcesPath, sep = '', file = filehandle)
      print('MAKEFILE_ID=', filename.rsplit('.make', 1)[0], sep = '', file = filehandle)
      print(file = filehandle)
  
      # Define the stdout and stderr.
      print('### Standard output and error files.', file = filehandle)
      print('STDOUT=$(PWD)/$(MAKEFILE_ID).stdout', sep = '', file = filehandle)
      print('STDERR=$(PWD)/$(MAKEFILE_ID).stderr', sep = '', file = filehandle)
      print('COMPLETE_OK=$(PWD)/$(MAKEFILE_ID).ok', sep = '', file = filehandle)
      print('EXECUTED=$(PWD)/$(MAKEFILE_ID).executed', sep = '', file = filehandle)
      print(file = filehandle)
  
      # Remove file on failed execution.
      print('### If the pipeline terminates unexpectedly, delete all files that were in', file = filehandle)
      print('### the process of being generated.', file = filehandle)
      print('.DELETE_ON_ERROR:', file = filehandle)
      print(file = filehandle)
  
      # The paths to the executables are added by phase later.
      print('### Executable paths.', file = filehandle)

  # If a single makefile is being output, find all the unique tools used in the pipeline.
  def addUniqueExecutables(self, graph, struct):
    allTools = []

    # Loop over all phases and all contained task and identify all tools.
    for phase in struct.phaseInformation:
      phaseTools = []
      for task in struct.phaseInformation[phase].tasks:
        tool = graph.getGraphNodeAttribute(task, 'tool')
        if tool in self.toolPaths: phaseTools.append(self.toolPaths[tool])

      # Remove tools that appear multiple times.
      phaseTools = set(phaseTools)

      # If there are multiple phases, write the tools for the phase to all makefiles in that
      # phase.
      if self.isMultipleMakefiles:
        for key in self.filenames:
          if key.startswith(str(phase)):
            filename = self.filenames[key]
            for tool in phaseTools: print(str(tool), file = self.filehandles[filename])
            print(file = self.filehandles[filename])

      # Add the tools for this phase to the list of tools for the pipeline.
      allTools.extend(phaseTools)
 
    # Having colleted all tools, remove duplicates and write to a single makefile, if required.
    if not self.isMultipleMakefiles:
      for tool in list(set(allTools)): print(str(tool), file = self.singleFilehandle)
      print(file = self.singleFilehandle)

  # List phony arguments. This is used solely for the file created on successful execution of the pipeline.
  def addPhony(self):
    for filename in self.filenamesList:
      print('### List all PHONY targets. These are targets that are not actual files.', file = self.filehandles[filename])
      print('.PHONY: DELETE_COMPLETE_OK', filename, file = self.filehandles[filename])
      print(file = self.filehandles[filename])

  # Get the intermediate and output files for the whole pipeline.
  def getAllOutputs(self, struct):

    # Loop over all the phases, subphases and divisions.
    allIntermediates = []
    allOutputs       = []
    intermediates    = {}
    outputs          = {}
    for phase in struct.phaseInformation:
      subphases = struct.phaseInformation[phase].numberSubphases
      divisions = struct.phaseInformation[phase].numberDivisions
      for subphase in range(1, subphases + 1):
        for division in range(1, divisions + 1):

          # Store the intermediates and outputs, keyed by the phase, subphase and division.
          key = str(phase) + str(subphase) + str(division)

          intermediates[key] = []
          outputs[key]       = []
          for task in struct.phaseInformation[phase].tasks:
            intermediates[key].extend(self.executionInfo[task].intermediates[subphase][division])
            outputs[key].extend(self.executionInfo[task].outputs[subphase][division])

          # Remove output files that are also marked as intermediates.
          outputs[key] = list(set(outputs[key]) - set(intermediates[key]))

          # If there are multiple makefiles, add the intermediate and output files to the relevant
          # makefile.
          if self.isMultipleMakefiles:
            filename   = self.filenames[key]
            filehandle = self.filehandles[filename]
            self.addIntermediateFiles(intermediates[key], filename, filehandle)
            self.addOutputFiles(outputs[key], filehandle)

          # Add the outputs and intermediates to the totla lists.
          allOutputs.extend(outputs[key])
          allIntermediates.extend(intermediates[key])

    # Determine if there are duplicate output files.
    duplicates = [x for x, y in collections.Counter(allOutputs).items() if y > 1]
    if len(duplicates) != 0: self.errors.duplicateOutputFiles(duplicates)

    # Add the intermediate and output files to the single makefile, if required.
    if not self.isMultipleMakefiles:
      self.addIntermediateFiles(allIntermediates, self.singleFilename, self.singleFilehandle)
      self.addOutputFiles(allOutputs, self.singleFilehandle)

      # Collapse all the outputs and intermediates into the first key (111) and remove outputs that
      # are present in the intermediates. An intermediate task can be an output when there are multiple
      # makefiles, since the file could be deleted in a subsequent makefile. For a single makefile,
      # however, all intermediates must be removed.
      buildIntermediates = []
      buildOutputs       = []
      for key in outputs:
        buildIntermediates.extend(intermediates[key])
        buildOutputs.extend(outputs[key])
      outputs[str(111)] = list(set(buildOutputs) - set(buildIntermediates))

    # Return a list of final outputs.
    return outputs

  # Add intermediate files to the makefile.
  def addIntermediateFiles(self, intermediates, filename, filehandle):

    # Write intermediate files to the makefile header. Files marked as intermediate are removed during
    # execution of the pipeline. By being marked as intermediate, reexecution of the pipeline will not
    # commence to regenerate the intermediate files.
    print('### The following files are intermediates. If the pipeline is rerun, rules for creating', file = filehandle)
    print('### will not be rerun unless files prior to these rules have been updated.', file = filehandle)
    print('.INTERMEDIATE: ', filename, end = ' ', file = filehandle)

    # Add all the intermediates to the makefile.
    for intermediate in intermediates: print(intermediate, end = ' ', file = filehandle)
    print(file = filehandle)
    print(file = filehandle)

  # Add output files to the makefile.
  def addOutputFiles(self, outputs, filehandle):

    # List all the output files created by this makefile.
    print('### List all of the files that are required outputs of the pipeline.', file = filehandle)
    print('all: DELETE_COMPLETE_OK $(COMPLETE_OK) ', end = '', file = filehandle)

    # Add all the output files to the makefile.
    for output in outputs: print(output, end = ' ', file = filehandle)
    print(file = filehandle)
    print(file = filehandle)

  # Prior to pipeline execution, remove the 'ok' file prodiced by a previous successful execution.
  def removeOk(self):
    for filename in self.filenamesList:
      filehandle = self.filehandles[filename]
      print('### Remove the file indicating successful completion of the pipeline. This file needs', file = filehandle)
      print('### to be recreated if the pipeline is rerun to indicate successful completion.', file = filehandle)
      print('DELETE_COMPLETE_OK:', file = filehandle)
      print('\t@rm -f $(EXECUTED)', file = filehandle)
      print('\t@rm -f $(COMPLETE_OK)', file = filehandle)
      print(file = filehandle)

  # Add the command lines to the makefiles.
  def addCommandLines(self, graph, struct, phase, subphase, division):

    # Loop over the tasks for this makefile adding the command lines.
    for task in struct.phaseInformation[phase].tasks:
      isInputStream  = graph.getGraphNodeAttribute(task, 'isInputStream')
      isOutputStream = graph.getGraphNodeAttribute(task, 'isOutputStream')

      # If this task outputs to a stream, no information should be written to the makefiles at this point.
      # All of the tasks that are part of the stream should be processed, so that the list of dependencies
      # and outputs can be constructed properly. If the task does not accept an input stream, then this is
      # the first task in the set of piped tools, so a data structure should be initialised.
      if isOutputStream:
        if not isInputStream: info = streamingInformation()
        self.storeStreamingTaskInformation(info, subphase, division, task, isLast = False)

      # If this task accepts an input stream and isn't outputting to a stream, all of the stored information
      # as well as the information for this task can be written to file.
      elif isInputStream:
        self.storeStreamingTaskInformation(info, subphase, division, task, isLast = True)
        self.writeStreamingInformation(graph, info, phase, subphase, division, task)

      # If this does not accept a stream or output to a stream, just write the information to the makefile.
      else: self.writeStandardInformation(graph, phase, subphase, division, task)

  # Update the stored information for tasks piped together.
  def storeStreamingTaskInformation(self, info, subphase, division, task, isLast):

    # Add this task to the list of tasks that are streamed together.
    info.tasks.append(task)

    # Update the list of task dependencies. This is all of the dependencies for the current
    # task minus any files that are streamed.
    for dependency in self.executionInfo[task].dependencies[subphase][division]:
      if dependency not in info.streamedFiles and dependency not in info.dependencies: info.dependencies.append(dependency)

    # Now loop over all of the outputs for the task. If the output file is being piped, this
    # should not be included in the list of outputs.
    # FIXME FOR NOW ASSUMING THAT ALL OUTPUTS ARE STREAMED.
    if isLast:
      for output in self.executionInfo[task].outputs[subphase][division]: info.outputs.append(output)
    else:
      for output in self.executionInfo[task].outputs[subphase][division]: info.streamedFiles.append(output)

    # Loop over all of the intermediate files (e.g. the files that can be deleted after this task is
    # complete) and store these files. These will be deleted at the end of the piped tasks.
    for intermediate in self.executionInfo[task].intermediates[subphase][division]:
      if intermediate not in info.streamedFiles and intermediate not in info.intermediates: info.intermediates.append(intermediate)

    # Finally, store the command line for the task.
    for line in self.executionInfo[task].commands[subphase][division]: info.commands.append(line)

  # Write information to the makefile for a set of piped tasks.
  def writeStreamingInformation(self, graph, info, phase, subphase, division, task):

    # Get the filename and filehandle.
    filename   = self.filenames[str(phase) + str(subphase) + str(division)]
    filehandle = self.filehandles[filename]

    print('### Command line information for the following piped tasks:', file = filehandle)
    print('### ', end = '', file = filehandle)
    for i in range(0, len(info.tasks) - 1): print(info.tasks[i], end = ', ', file = filehandle)
    print(info.tasks[-1], '...', sep = '', file = filehandle)

    # Only include the first output in the rule. If there are additional outputs, these are handled after
    # the rule in the makefile.
    print(info.outputs[0], ':', sep = '', end = ' ', file = filehandle)
    for dependency in info.dependencies: print(dependency, end = ' ', file = filehandle)
    print(file = filehandle)
  
    # Print to screen the tasks being executed.
    print('\t@echo -e "Executing tasks: ', end = '', file = filehandle)
    for i in range(0, len(info.tasks) - 1): print(info.tasks[i], end = ', ', file = filehandle)
    print(info.tasks[-1], '...\c"', sep = '', file = filehandle)
  
    # Print the command line.
    for line in info.commands: print(line, file = filehandle)
  
    # Include an additional rule if the task created multiple output files.
    # FIXME
    if len(info.outputs) > 1: self.multipleOutputFiles(filehandle, filename, info, subphase, division)

    # If any files are to be deleted after this task, delete them.
    if info.intermediates:
      print('\t### Delete intermediate files that are no longer required.', file = filehandle)
      for intermediate in info.intermediates: print('\t@rm -f ', intermediate, sep = '', file = filehandle)
      print(file = filehandle)

  # Write information to the makefile for a task with no streaming.
  def writeStandardInformation(self, graph, phase, subphase, division, task):

    # Get the filename and filehandle.
    filename   = self.filenames[str(phase) + str(subphase) + str(division)]
    filehandle = self.filehandles[filename]

    print('### Command line information for the following task:', file = filehandle)
    print('### ', task, ' (', graph.getGraphNodeAttribute(task, 'tool'), ')', sep = '', file = filehandle)
  
    # Only include the first output in the rule. If there are additional outputs, these are handled after
    # the rule in the makefile.
    print(self.executionInfo[task].outputs[subphase][division][0], ':', sep = '', end = ' ', file = filehandle)
    for dependency in self.executionInfo[task].dependencies[subphase][division]: print(dependency, end = ' ', file = filehandle)
    print(file = filehandle)

    # Print to screen the task being executed.
    print('\t@echo -e "Executing task: ', task, '...\c"', sep = '', file = filehandle)
  
    # Print the command line.
    for line in self.executionInfo[task].commands[subphase][division]: print(line, file = filehandle)

    # Include an additional rule if the task created multiple output files.
    if len(self.executionInfo[task].outputs[subphase][division]) > 1:
      self.multipleOutputFiles(filehandle, filename, self.executionInfo[task], subphase, division)

    # If any files are to be deleted after this task, delete them.
    if self.executionInfo[task].intermediates[subphase][division]:
      print('### Delete intermediate files that are no longer required.', file = filehandle)
      print('\t@echo -e "Deleting temporary files...\\c"', file = filehandle)
      for intermediate in self.executionInfo[task].intermediates[subphase][division]: print('\t@rm -f ', intermediate, sep = '', file = filehandle)
      print('\t@echo -e "complete."', file = filehandle)
      print(file = filehandle)

  # output is included in the rule for the additional task.
  def multipleOutputFiles(self, filehandle, filename, data, subphase, division):
    print('### Rule for checking that all outputs of previous task exist.', file = filehandle)
    for counter in range(1, len(data.outputs[subphase][division]) - 1):
      print(data.outputs[subphase][division][counter], end = ' ', file = filehandle)
    print(data.outputs[subphase][division][-1], end = ': ', file = filehandle)
    for dependency in data.dependencies[subphase][division]: print(dependency, end = ' ', file = filehandle)

    # Add the primaryOutput to the list of dependencies. This is the file that is listed as the output for
    # the rule. If running with multiple threads and none of the files exist, the original rule is executed
    # since the output file does not exist. This rule for the additional outputs is the executed in parallel
    # since none of these additional files exist either. By including the primaryOutput as a dependency, we
    # ensure that the original rule gets to run first and this check isn't performed until it has been
    # completed.
    print(data.outputs[subphase][division][0], file = filehandle)
    print('\t@if test -f $@ || test -d $@; then \\', file = filehandle)
    print('\t  touch $@; \\', file = filehandle)
    print('\telse \\', file = filehandle)
    print('\t  rm -f ', data.outputs[subphase][division][0], "; \\", sep = '', file = filehandle)
    print('\t  $(MAKE) --no-print-directory -f $(PWD)/', filename, ' ', data.outputs[subphase][division][0], '; \\', sep = '', file = filehandle)
    print('\tfi', file = filehandle)
    print(file = filehandle)

  # Write the final instructions to the makefile.
  def completeFile(self, outputs):
 
    # Loop over all files and add the final text to them all.
    for filename in self.filenamesList:
      filehandle = self.filehandles[filename]
      key        = self.keys[filename]

      # Prior to closing the file, include instructions for generating an 'ok' file indicating that the
      # makefile was successfully executed and delete the makefile.
      print('### Generate a file indicating successful execution of makefile', file = filehandle)
      print('$(COMPLETE_OK): ', end = '', file = filehandle)
  
      # Add all of the outputs generated by this makefile to the list of dependencies. The 'ok' file is
      # only created if the pipeline ran successfully and generated everything required.
      for filename in outputs[key]: print(filename, end = ' ', file = filehandle)
      print(file = filehandle)
      print('\t@rm -f $(MAKEFILE_ID).make', file = filehandle)

      # If any of the rules were executed, the file defined by $(EXECUTED) will have been created. If this
      # file does not exist, nothing was executed. This will result if all the files already existed and
      # make determined that there was no need to execute any rules. If this is the case, inform the user.
      print('\t@if test ! -f $(EXECUTED); then \\', file = filehandle)
      print('\t  echo \'===================================\'; \\', file = filehandle)
      print('\t  echo \'  WARNING: No new files generated.\'; \\', file = filehandle)
      print('\t  echo \'===================================\'; \\', file = filehandle)
      print('\t  echo ; \\', file = filehandle)
      print('\t  echo \'All required output files already exist, so none of the tasks in the pipeline were executed.\'; \\', file = filehandle)
      print('\t  echo \'To force execution of the pipeline remove output files prior to execution of gkno.\'; \\', file = filehandle)
      print('\telse \\', file = filehandle)
      print('\t  touch $(COMPLETE_OK); \\', file = filehandle)
      print('\tfi', file = filehandle)
      print('\t@rm -f $(EXECUTED)', file = filehandle)

  # Close the makefiles.
  def closeFiles(self):
    for filename in self.filenamesList:
      filehandle = self.filehandles[filename]
      fh.fileHandling.closeFile(filehandle)

  # Return the argument to be written to the command line (and consequently, that stored in the commands
  # data structure). It is usually the case that the gkno argument does not correspond to the tool
  # argument.
  def getToolArgument(self, graph, task, nodeId, isInput):
    inputInstructions  = graph.getArgumentAttribute(nodeId, task, 'inputStreamInstructions')
    outputInstructions = graph.getArgumentAttribute(task, nodeId, 'outputStreamInstructions')

    # Determine streaming instructions, beginning with if this is an input accepting a stream.
    if graph.getGraphNodeAttribute(task, 'isInputStream') and inputInstructions:

      # If the argument should be omitted.
      if inputInstructions['argument'] == 'omit': return None
 
      # Return the supplied value to use as the argument.
      else: return str(inputInstructions['argument'])

    # Now handle outputting to a stream.
    elif graph.getGraphNodeAttribute(task, 'isOutputStream') and outputInstructions:
  
      # Check for the different allowed modifications to the argument. If the argument is listed as omit,
      # the argument should be omitted from the command line (not replaced with another value). In this
      # case, return None.
      if outputInstructions['argument'] == 'omit': return None
  
      # If the instructions are none of the above, the argument should be replaced with the supplied value.
      # In this case, return the value supplied.
      else: return str(outputInstructions['argument'])

    # Otherwise, use the other instructions.
    else:
  
      # If the argument is for an input file.
      if isInput:
        commandLineArgument = graph.getArgumentAttribute(nodeId, task, 'commandLineArgument')
        modifyArgument      = graph.getArgumentAttribute(nodeId, task, 'modifyArgument')
  
      # And if the argument is for an output file.
      else: 
        commandLineArgument = graph.getArgumentAttribute(task, nodeId, 'commandLineArgument')
        modifyArgument      = graph.getArgumentAttribute(task, nodeId, 'modifyArgument')
  
      # Return the argument to be used on the command line.
      if modifyArgument == 'omit': return None

      # If the output should be redirected to stdout, there should be no command, just the redirection.
      elif modifyArgument == 'stdout': return '>>'
      else: return commandLineArgument

  #######################################################
  ### Static methods for getting makefile information ###
  #######################################################

  # If the input/output is a stream, determine how the value should be written to the command line.
  @staticmethod
  def getStreamValue(graph, source, target, value, isInput, isStub):
    if isInput: instructions = graph.getArgumentAttribute(source, target, 'inputStreamInstructions')
    else: instructions = graph.getArgumentAttribute(source, target, 'outputStreamInstructions')

    # Return the value based on the instructions.
    if instructions['value'] == 'omit': return None

    # If none of the above instructions are set, return the value supplied in the instructions. This is
    # what will be used in place of the value.
    else: return str(instructions['value'])

  # Similar method to the getToolArgument except for the associated value.
  @staticmethod
  def getValue(graph, source, target, value, isInput, isStub, stubExtension):

    # If the argument is for an input file.
    modifyValue = graph.getArgumentAttribute(source, target, 'modifyValue')

    # Check if the value should be included in quotation marks.
    inQuotations = graph.getArgumentAttribute(source, target, 'includeInQuotations')

    # If this is a stub, add the extension to the value and return.
    if isStub:
      if not graph.getArgumentAttribute(source, target, 'primaryStubNode'): return None
      else: 
        try: updatedValue = value.rstrip(stubExtension)
        except: updatedValue = value
        updatedValue = updatedValue.rstrip('.') if updatedValue.endswith('.') else updatedValue
        if inQuotations: return str('"' + updatedValue + '"')
        else: return updatedValue

    # If this is not a stub, return the argument to be used on the command line.
    if modifyValue == 'omit': return None

    # Include the value in quotations, if requested.
    elif inQuotations: return str('"' + value + '"')

    # Otherwise, just return the original value.
    else: return value

  # Build a line of the command line.
  @staticmethod
  def buildLine(argument, delimiter, value):
    hasValue = False if not value and value != 0 else True

    # If neither the argument or the value are populated, return None.
    if not argument and not hasValue: return None

    # If the value is defined, but the argument is not, this is a tool that does not use arguments on the
    # command line and so the command should be the value only.
    elif not argument: return '\t' + str(value) + ' \\'

    # If only the argument is defined, this is a flag, so only the argument is returned.
    elif not hasValue: return '\t' + str(argument) + ' \\'

    # Finally, if both are defined, return the correctly delimited argument, value pair.
    else: return '\t' + str(argument) + str(delimiter) + str(value) + ' \\'
    line = '\t' + str(argument) + str(delimiter) + str(value) + ' \\'

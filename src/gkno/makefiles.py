#!/bin/bash/python

from __future__ import print_function
from copy import deepcopy
import collections

import fileHandling as fh
import makefileErrors
import pipelineConfigurationErrors as pce
import stringOperations as stringOps

import json
import os
import sys

# Define a class to hold information about the command line.
class commandLineInformation():
  def __init__(self, graph, superpipeline, struct, task):

    # Store the task and tool.
    self.task     = task
    self.tool     = graph.getGraphNodeAttribute(task, 'tool')
    self.toolData = superpipeline.toolConfigurationData[self.tool]

    # Store if the task is greedy or consolidates divisions.
    self.isGreedy      = graph.getGraphNodeAttribute(task, 'isGreedy')
    self.isConsolidate = graph.getGraphNodeAttribute(task, 'isConsolidate')

    # Determine the number of command lines to be created for the task. This can be determined by finding
    # the phase in which the task resides in the pipeline execution structure, and then determining the
    # number of subphases and divisions within the phase. The total number of command lines is equal to the
    # product of these two values.
    self.phase              = struct.task[task]
    self.numberSubphases    = struct.phaseInformation[self.phase].numberSubphases
    self.numberDivisions    = struct.phaseInformation[self.phase].numberDivisions
    self.numberCommandLines = self.numberSubphases * self.numberDivisions

    # Get the executable information.
    self.executable = self.toolData.executable
    self.modifier   = self.toolData.modifier
    self.path       = self.toolData.path
    self.precommand = self.toolData.precommand

    # Get the argument delimiter for this tool.
    self.delimiter = self.toolData.delimiter

    # Define and store the path to the executable.
    self.toolID = str(self.tool.upper() + '-PATH')

    # Store the command lines for this task. This is indexed by the subphase and the division. Store
    # the dependencies, intermediates, output files and files for standard out to write to, for each
    # command line with the same structure.
    self.commands      = {}
    self.dependencies  = {}
    self.intermediates = {}
    self.outputs       = {}
    self.stdouts       = {}
    for i in range(1, self.numberSubphases + 1):
      self.commands[i]      = {}
      self.dependencies[i]  = {}
      self.intermediates[i] = {}
      self.outputs[i]       = {}
      self.stdouts[i]       = {}
      for j in range(1, self.numberDivisions + 1):
        self.commands[i][j]      = []
        self.dependencies[i][j]  = []
        self.intermediates[i][j] = []
        self.outputs[i][j]       = []
        self.stdouts[i][j]       = str('\t>> $(STDOUT) \\')

# Define a class that is a data structure for holding information for tasks that are piped
# together.
class streamingInformation:
  def __init__(self):
    self.commands       = []
    self.dependencies   = []
    self.intermediates  = []
    self.outputs        = []
    self.streamedFiles  = []
    self.tasks          = []

# Define a class to build and manipulate makefiles.
class makefiles:
  def __init__(self):

    # Handle errors associated with makefile construction.
    self.errors = makefileErrors.makefileErrors()

    # Store the paths of all the tools executed in the pipeline.
    self.toolPaths = {}

    # Store information including command lines, dependencies and outputs for each task.
    self.executionInfo = {}

    # For each intermediate file, store where in the pipeline it can be deleted.
    self.deleteAfterTask = {}
    self.fileDeletion = {}

    # Record if multiple makefiles are to be generated.
    self.isMultipleMakefiles = False

    # Store the user specified ID to add to all makefile filesnames.
    self.makefileId = None

    # Store the makefile names and file handles.
    self.filehandles   = {}
    self.filenames     = {}
    self.filenamesList = []
    self.keys          = {}

    # Store the name of the makefile and the filehandle if there is only a single file.
    self.singleFilename   = None
    self.singleFilehandle = None

    # Store the outputs generated by each makefile.
    self.makefileOutputs = {}

  # Generate the command lines associated with a task.
  def generateCommandLines(self, graph, superpipeline, struct):

    # Loop over all the tasks in the pipeline, generating the command lines for each task.
    for task in graph.workflow:

      # Get the tool used to run the task and the data contained in the configuration file.
      tool     = graph.getGraphNodeAttribute(task, 'tool')
      toolData = superpipeline.toolConfigurationData[tool]

      # Determine whether the input or the output from this task are streams.
      isInputStream  = graph.getGraphNodeAttribute(task, 'isInputStream')
      isOutputStream = graph.getGraphNodeAttribute(task, 'isOutputStream')

      # Loop over all of the nodes and get the arguments that are going to be used and the
      # node IDs to which they connect. This will then be used to allow the arguments to 
      # be parsed in the order specified.
      inputArguments  = self.getArguments(graph, task, graph.getInputFileNodes(task), isInput = True)
      optionArguments = self.getArguments(graph, task, graph.getOptionNodes(task), isInput = True)
      outputArguments = self.getArguments(graph, task, graph.getOutputFileNodes(task), isInput = False)

      # Check if the tool arguments need to be included in a defined order.
      argumentOrder = toolData.argumentOrder
      if not argumentOrder: argumentOrder = inputArguments.keys() + optionArguments.keys() + outputArguments.keys()

      # Generate a data structure for building the command line.
      data = commandLineInformation(graph, superpipeline, struct, task)
  
      # Store the tools path in the global makefiles dictionary toolPaths. If the path is listed
      # as 'none', do not include the path.
      if data.tool not in self.toolPaths and data.path != 'none': self.toolPaths[data.tool] = str(data.toolID + '=$(TOOL_BIN)/' + data.path)
  
      # The output of the method is a list of command lines, one command line for each execution
      # of the task. Each command line is itself a list of the command line executable and arguments.
      # First determine the command line executable.
      path = ' ' if data.path == 'none' else ' $(' + data.toolID + ')/'
      command = str(data.precommand + path + data.executable + ' ' + data.modifier).rstrip(' ').strip(' ')
  
      # Add the executable to the command lines and initialise the lists of dependencies and outputs
      # to have the same length as the commands.
      for i in range(1, data.numberSubphases + 1):
        for j in range(1, data.numberDivisions + 1):

          # If the task uses an input data stream, only include the name of the command.
          if isInputStream: data.commands[i][j].append('\t' + command + ' \\')

          # If the task isn't accepting an input stream, but does output to a stream, then it is the first
          # in the set of streamed tasks. The variable TOT requires initializing to ensure that the pipe
          # ran successfully.
          elif isOutputStream: data.commands[i][j].append('\t@TOT=0; ' + command  + ' \\')

          # If this is a standalone task, just the '@' symbol and the command are required.
          else: data.commands[i][j].append('\t@' + command + ' \\')

      # Search predecessor nodes to find if there are any predecessor nodes that are links only. Any values
      # for these links should be included as dependencies for this task.
      self.getLinks(graph, task, data)

      # Loop over the argument order for the tool, getting information from the nodes in the correct
      # order. The argument order is populated with the arguments in random order if the order wasn't
      # specified in the configuration file.
      for argument in argumentOrder:
        if argument in optionArguments:
          for nodeId in optionArguments[argument]: self.addOption(graph, task, data, nodeId)
        if argument in inputArguments:
          for nodeId in inputArguments[argument]: self.addInput(graph, task, data, nodeId)
        if argument in outputArguments:
          for nodeId in outputArguments[argument]: self.addOutput(graph, task, data, nodeId)

      # Finish the command lines with calls to write to stdout and stdin and indicating that the task is complete.
      # These values are modified based on whether the task is outputting to a stream or not.
      for i in range(1, data.numberSubphases + 1):
        for j in range(1, data.numberDivisions + 1):

          # If the task outputs to a stream, include the pipe.
          if isOutputStream:
            data.commands[i][j].append('\t2>> $(STDERR) \\')
            data.commands[i][j].append('\t| \\')

          # If the task doesn't output to a stream, but accepts a stream as input, include text to ensure that the
          # exist status of the pipeline and not just the last task is handled.
          elif isInputStream:
            data.commands[i][j].append(data.stdouts[i][j])
            data.commands[i][j].append('\t2>> $(STDERR); \\')
            data.commands[i][j].append('\tfor i in $${PIPESTATUS[@]}; do TOT=$$(( $$TOT + $$i )); done; \\')
            data.commands[i][j].append('\tif [[ $$TOT != 0 ]]; \\')
            data.commands[i][j].append('\tthen rm -f ' + str(data.outputs[i][j][0]) + '; \\')
            data.commands[i][j].append('\techo -e "failed."; \\')
            data.commands[i][j].append('\telse \\') 
            data.commands[i][j].append('\techo -e "completed successfully."; \\')
            data.commands[i][j].append('\tfi')
            data.commands[i][j].append('\t@touch $(EXECUTED)')
            data.commands[i][j].append('')

          # If this was a single task, finish the task.
          else:
            data.commands[i][j].append(data.stdouts[i][j])
            data.commands[i][j].append('\t2>> $(STDERR)')
            data.commands[i][j].append('\t@echo -e "completed successfully."')
            data.commands[i][j].append('\t@touch $(EXECUTED)')
            data.commands[i][j].append('')

      # Store the command lines for the task.
      self.executionInfo[task] = data

  # Find all the arguments for a task.
  def getArguments(self, graph, task, nodeIds, isInput):
    arguments = {}
    for nodeId in nodeIds:

      # If the node is a child, ignore it. In order to ensure that filenames will appear in the correct order of divisions,
      # the parent node must appear first in the list, followed by the children in division order.
      if not graph.getGraphNodeAttribute(nodeId, 'isChild'):
        if isInput: argument = graph.getArgumentAttribute(nodeId, task, 'longFormArgument')
        else: argument = graph.getArgumentAttribute(task, nodeId, 'longFormArgument')
  
        if argument in arguments: arguments[argument].append(nodeId)
        else: arguments[argument] = [nodeId]

        # If this is an input and a parent node, add the children to the list in the correct order.
        if isInput and graph.getGraphNodeAttribute(nodeId, 'isParent'):
          for child in graph.getGraphNodeAttribute(nodeId, 'children'): arguments[argument].append(child)

    # Return the arguments.
    return arguments

  # Search predecessors for edges marked as links only. These edges will not be used with arguments, but the task dependencies
  # need to be updated.
  def getLinks(self, graph, task, data):

    # Loop over all task predecessors.
    for predecessor in graph.graph.predecessors(task):

      # Only proceed with edges marked as links.
      if graph.getArgumentAttribute(predecessor, task, 'isLinkOnly'):
        counter = 0
        values  = graph.getGraphNodeAttribute(predecessor, 'values')
        for i in range(1, data.numberSubphases + 1):
          for j in range(1, data.numberDivisions + 1):
            data.dependencies[i][j].append(values[counter])
            counter += 1

  # Add option values to the command lines.
  def addOption(self, graph, task, data, nodeId):

    # Get the argument, values and data type for the option node.
    argument = self.getToolArgument(graph, task, nodeId, isInput = True)
    values   = graph.getGraphNodeAttribute(nodeId, 'values')
    dataType = graph.getArgumentAttribute(nodeId, task, 'dataType')

    # Check if this argument requires replacement of substrings.
    if graph.getArgumentAttribute(nodeId, task, 'isReplaceSubstring'):
      values = self.replaceSubstrings(graph.getArgumentAttribute(nodeId, task, 'replaceSubstring'), values)

    # Determine if this option can be specified multiple times on the command line, or if this
    # option is used to create divisions..
    isAllowMultipleValues = graph.getArgumentAttribute(nodeId, task, 'allowMultipleValues')
    isCreateDivision      = graph.getGraphNodeAttribute(nodeId, 'isCreateDivision')

    # If the argument is a flag, it cannot be given multiple values.
    if dataType == 'flag' and len(values) > 1: print('ERROR - makefiles.addOption - 3'); exit(1)

    # Regardless of the number of values supplied, each subphase needs to receive the same values.
    # Any differences between command lines would occur for multiple divisions. So, loop over all
    # divisions and apply the same command line to each subphase within the division.
    for i in range(1, data.numberDivisions + 1):
      lines = []

      # If the option creates the divisions, create the line based on the ith value. 
      if isCreateDivision and not isAllowMultipleValues:
        #TODO ERROR
        if len(values) != data.numberDivisions: print('ERROR - makefiles.addOption - 1', task, nodeId); exit(1)
        lineValue = self.getValue(graph, nodeId, task, values[i - 1], isInput = True, isStub = False, stubExtension = None)
        lines.append(self.buildLine(argument, data.delimiter, lineValue))

        # Add the options to the command lines for each subphase.
        for j in range(1, data.numberSubphases + 1): data.commands[j][i].extend(lines)

      # If this option does not create the divisions, but there are multiple values, they must all be applied on the
      # same command line. Again, this cannot be a flag.
      elif len(values) > 1:

        # Check if the option is permitted to be applied multiple times. If so, add all values to the same command line.
        if isAllowMultipleValues:
          for value in values:
            lineValue = self.getValue(graph, nodeId, task, value, isInput = True, isStub = False, stubExtension = None)
            lines.append(self.buildLine(argument, data.delimiter, lineValue))

          # Add the options to the command lines for each subphase.
          for j in range(1, data.numberSubphases + 1): data.commands[j][i].extend(lines)

        # If there are the same number of values as there are subphases, add the values accordingly.
        elif len(values) == data.numberSubphases:
          for j in range(1, data.numberSubphases + 1):
            lineValue = self.getValue(graph, nodeId, task, values[j - 1], isInput = True, isStub = False, stubExtension = None)
            line      = self.buildLine(argument, data.delimiter, lineValue)

            # Add the options to the command lines for each subphase.
            if line: data.commands[j][i].append(line)

        # If neither of the above consitions are true, terminate.
        else: print('ERROR - makefiles.addOption - 2', argument, len(values)); exit(1)

      # If there is only a single value, build the line considering if this is a flag.
      else:

        # If the option is a flag, there is no value to output, so set this to a blank.
        if dataType == 'flag':
          lineValue = ''
          if values[0] != 'set': argument = ''

        # If the value is set, the flag should be set on the command line, otherwise, this should be left blank.
        else: lineValue = self.getValue(graph, nodeId, task, str(values[0]), isInput = True, isStub = False, stubExtension = None)

        # Only add the line to the lines if the flag is set.
        line = self.buildLine(argument, data.delimiter, lineValue)
        if line: lines.append(line)

        # Add the options to the command lines for each subphase.
        for j in range(1, data.numberSubphases + 1): data.commands[j][i].extend(lines)

  # Replace substrings in a list of values.
  def replaceSubstrings(self, substrings, values):
    modifiedValues = []

    # Loop over all values
    for value in values:
      modifiedValue = value

      # Loop over all strings to be replaced.
      for toReplace, replaceWith in substrings:
        modifiedValue = modifiedValue.replace(toReplace, replaceWith)

      # Add the complete value to the modified list.
      modifiedValues.append(modifiedValue)

    # Return the updated values.
    return modifiedValues

  # Add input files to the command line.
  def addInput(self, graph, task, data, nodeId):

    # Determine the division to which these values belong, or if this is an argument that should be applied to all
    # divisions. Also, determine the parent node if this is a child and use the parent to determine all information,
    # e.g. streaming etc.
    divisionId   = 1
    isGlobal     = False
    parentNodeId = nodeId
    if graph.getGraphNodeAttribute(nodeId, 'isChild'):
      divisionId   = graph.getGraphNodeAttribute(nodeId, 'divisionID') + 1
      parentNodeId = graph.getGraphNodeAttribute(nodeId, 'parent')
    else:
      if not graph.getGraphNodeAttribute(nodeId, 'children'): isGlobal = True

    # Get the argument, values and data type for the option node. Use the parentNodeId for getting the argument. All
    # child nodes still use the same command line argument.
    argument = self.getToolArgument(graph, task, parentNodeId, isInput = True)
    values   = graph.getGraphNodeAttribute(nodeId, 'values')
    dataType = graph.getArgumentAttribute(parentNodeId, task, 'dataType')

    # If this task consolidates files then it should be treated as global.
    if graph.getGraphNodeAttribute(task, 'consolidate'): isGlobal = True

    # Determine if this option can be specified multiple times on the command line and if the task is listed
    # as being greedy.
    isAllowMultipleValues = graph.getArgumentAttribute(parentNodeId, task, 'allowMultipleValues')
    isGreedy              = graph.getGraphNodeAttribute(task, 'isGreedy')

    # Check if this node contains intermediate files.
    isIntermediate = graph.getGraphNodeAttribute(parentNodeId, 'isIntermediate')

    # Determine if this is a stub.
    isStub         = graph.getArgumentAttribute(parentNodeId, task, 'isStub')
    stubExtension  = graph.getArgumentAttribute(parentNodeId, task, 'stubExtension')
    includeStubDot = graph.getArgumentAttribute(parentNodeId, task, 'includeStubDot')
    isPrimaryNode  = graph.getArgumentAttribute(parentNodeId, task, 'isPrimaryStubNode')

    # Determine if this argument is for a stream.
    isStream = graph.getArgumentAttribute(parentNodeId, task, 'isStream')

    # Convert the values into the form required on the command line.
    if isStream: lineValues = [self.getStreamValue(graph, parentNodeId, task, value, True, isStub) for value in values]
    else: lineValues = [self.getValue(graph, parentNodeId, task, value, True, isStub, stubExtension) for value in values]

    # If this task is greedy, check that the argument allows multiple values to be set and that there is only a single
    # subphase. Then create the command line.
    if isGreedy:
      #TODO ERROR
      if len(values) > 1:
        if not isAllowMultipleValues: print('ERROR - makefiles.addInput - 1'); exit(1)
        if data.numberSubphases > 1: print('ERROR - makefiles.addInput - 2'); exit(1)

    # Loop over the subphases and add the input files to the correct data structures. If this node is part of a division,
    # the divisionId has already been determined, so the values will be placed with the correct division.
    for subphase in range(1, data.numberSubphases + 1):
      lines = []

      # If this task is greedy, check that the argument allows multiple values to be set and that there is only a single
      # subphase. Then create the command line.
      if isGreedy or len(lineValues) == 1:

        # Loop over the values and add to the command line.
        for value in lineValues:
          lineValue = self.getValue(graph, nodeId, task, value, isInput = True, isStub = isStub, stubExtension = stubExtension)
          line      = self.buildLine(argument, data.delimiter, lineValue)
          if isStub and not isPrimaryNode: line = None
          if line: lines.append(line)

      # If the task isn't greedy and has multiple values, each value is used for a seperate subphase.
      elif len(lineValues) > 1:
        lineValue = self.getValue(graph, nodeId, task, lineValues[subphase - 1], isInput = True, isStub = isStub, stubExtension = stubExtension)
        line      = self.buildLine(argument, data.delimiter, lineValue)
        if isStub and not isPrimaryNode: line = None
        if line: lines.append(line)

      # If this is a file(s) that feeds into all divisions, loop over the divsions and add the files to
      # each division.
      if isGlobal: 
        for division in range(1, data.numberDivisions + 1):
          self.addDivisionInputs(graph, nodeId, data, subphase, division, values, lines, lineValues, isIntermediate, isStream, isGreedy)

      # If this node is a child, then the files are only to be used for this specific division. In this case
      # do not loop over the divisions, just add the files to the divisionId already determined.
      else: self.addDivisionInputs(graph, nodeId, data, subphase, divisionId, values, lines, lineValues, isIntermediate, isStream, isGreedy)

  # Add input files to the relevant structures.
  def addDivisionInputs(self, graph, nodeId, data, subphase, division, values, lines, lineValues, isIntermediate, isStream, isGreedy):
    updatedValues = []

    # Add the inputs to the command lines for each subphase.
    data.commands[subphase][division].extend(lines)

    # Check if a file location is defined. If so, prepend the file location to the values.
    fileLocation = graph.getGraphNodeAttribute(nodeId, 'fileLocation')
    if fileLocation:
      for value in values: updatedValues.append(str(fileLocation + value))
    else: updatedValues = values

    # Add the files to the dependencies or outputs for the command line (if not being streamed).
    if not isStream:
      if isGreedy and len(lineValues) > 1:
        for value in updatedValues: data.dependencies[subphase][division].append(str(value))
      elif len(values) > 1: data.dependencies[subphase][division].append(str(updatedValues[subphase - 1]))
      else: data.dependencies[subphase][division].append(str(updatedValues[0]))

  # Add input files to the command line.
  def addOutput(self, graph, task, data, nodeId):

    # Get the argument, values and data type for the option node.
    argument = self.getToolArgument(graph, task, nodeId, isInput = False)
    values   = graph.getGraphNodeAttribute(nodeId, 'values')
    dataType = graph.getArgumentAttribute(task, nodeId, 'dataType')

    # Check if this task has children. If so, the outputs for the different subphases will be attached to the child nodes.
    isParent = graph.getGraphNodeAttribute(nodeId, 'isParent')
    children = graph.getGraphNodeAttribute(nodeId, 'children')

    # Check if this node contains intermediate files.
    isIntermediate = graph.getGraphNodeAttribute(nodeId, 'isIntermediate')

    # Determine if this is a stub.
    isStub         = graph.getArgumentAttribute(task, nodeId, 'isStub')
    stubExtension  = graph.getArgumentAttribute(task, nodeId, 'stubExtension')
    includeStubDot = graph.getArgumentAttribute(task, nodeId, 'includeStubDot')
    isPrimaryNode  = graph.getArgumentAttribute(task, nodeId, 'isPrimaryStubNode')

    # Determine if this argument is for a stream.
    isStream = graph.getArgumentAttribute(task, nodeId, 'isStream')

    # Convert the values into the form required on the command line.
    if isStream: lineValues = [self.getStreamValue(graph, task, nodeId, value, False, isStub) for value in values]
    else: lineValues = [self.getValue(graph, task, nodeId, value, False, isStub, stubExtension) for value in values]

    # If this is a parent node, then the task has been split into divisions. The parent file node and it's children each
    # correspond to a division. Thus the values contained in them are for each subphase with the division. Begin by looping
    # over the values in the parent node. This corresponds to the first division, then each value is for each of the
    # subphases. Then loop over the children and populate the subphase outputs for each division.
    #
    # Deal with the first division. If there are multiple divisions, this is the values from the parent node. If there is
    # only a single division, this is the only node that exists.
    for subphase, value in enumerate(values):
      lineValue = lineValues[subphase]
      if isStub and not isPrimaryNode: line = None
      else: line = self.buildLine(argument, data.delimiter, lineValue)
      if line:

        # If this task outputs to stdout, update the stdouts data structure,
        if line.startswith('\t>>'): data.stdouts[subphase + 1][1] = str(line)
        else: data.commands[subphase + 1][1].append(line)

      # Add the files to the intermediates or outputs for the command line (do not add the values to the list of
      # inputs and intermediates if the files are being streamed).
      if not isStream:
        data.outputs[subphase + 1][1].append(str(value))

        # If this is an intermediate file, add to the list of intermediate files.
        if isIntermediate and str(value) not in data.intermediates[subphase + 1][1]:
          data.intermediates[subphase + 1][1].append(str(value))

          # Determine the task after which the file can be deleted.
          deleteAfterTask = graph.getGraphNodeAttribute(nodeId, 'deleteAfterTask')
          if deleteAfterTask not in self.deleteAfterTask: self.deleteAfterTask[deleteAfterTask] = {}
          if subphase + 1 not in self.deleteAfterTask[deleteAfterTask]: self.deleteAfterTask[deleteAfterTask][subphase + 1] = {}
          if 1 not in self.deleteAfterTask[deleteAfterTask][subphase + 1]: self.deleteAfterTask[deleteAfterTask][subphase + 1][1] = []

          # Determine the phase that the task is in.
          #key = str(subphase + 1) + str(1)
          #self.deleteAfterTask[deleteAfterTask].append((key, str(value)))
          self.deleteAfterTask[deleteAfterTask][subphase + 1][1].append(str(value))
          self.fileDeletion[str(value)] = deleteAfterTask

    # If there are multiple divisions, values for division 2 onwards are stored in the child nodes which are dealt with here.
    if isParent:
      for child in children:
        division = graph.getGraphNodeAttribute(child, 'divisionID') + 1
        lines    = []

        # Convert the values into the form required on the command line.
        values = graph.getGraphNodeAttribute(child, 'values')
        if isStream: lineValues = [self.getStreamValue(graph, task, nodeId, value, False, isStub) for value in values]
        else: lineValues = [self.getValue(graph, task, nodeId, value, False, isStub, stubExtension) for value in values]

        for subphase, value in enumerate(values):
          lineValue = lineValues[subphase]
          if isStub and not isPrimaryNode: line = None
          else: line = self.buildLine(argument, data.delimiter, lineValue)
          if line:
            if line.startswith('\t>>'): data.stdouts[subphase + 1][division] = str(line)
            else: data.commands[subphase + 1][division].append(line)

          # Add the files to the intermediates or outputs for the command line (do not add the values to the list of
          # inputs and intermediates if the files are being streamed).
          if not isStream:
            data.outputs[subphase + 1][division].append(str(value))
    
            # If this is an intermediate file, add to the list of intermediate files.
            if isIntermediate and str(value) not in data.intermediates[subphase + 1][division]: 
              data.intermediates[subphase + 1][division].append(str(value))
    
              # Determine the task after which the file can be deleted.
              deleteAfterTask = graph.getGraphNodeAttribute(nodeId, 'deleteAfterTask')
              if deleteAfterTask not in self.deleteAfterTask: self.deleteAfterTask[deleteAfterTask] = {}
              if subphase + 1 not in self.deleteAfterTask[deleteAfterTask]: self.deleteAfterTask[deleteAfterTask][subphase + 1] = {}
              if division not in self.deleteAfterTask[deleteAfterTask][subphase + 1]: self.deleteAfterTask[deleteAfterTask][subphase + 1][division] = []
    
              # Determine the phase that the task is in.
              #key = str(subphase + 1) + str(division)
              #self.deleteAfterTask[deleteAfterTask].append((key, str(value)))
              self.deleteAfterTask[deleteAfterTask][subphase + 1][division].append(str(value))
              self.fileDeletion[str(value)] = deleteAfterTask

  # Check if the value has the given extension and, if not, add it.
  def addStubExtension(self, value, extension, includeStubDot):
    if value.endswith(extension): return value
    else:
      updatedValue = str(value + '.' + extension) if includeStubDot else str(value + extension)
      return updatedValue

  # Move intermediate files so that they appear associated with the task after which they are deleted. This is only
  # necessary if multiple makefiles are being generated.
  def updateIntermediates(self, struct):

    if self.isMultipleMakefiles:

      # Define a new dictionary for the intermediates. Intermediate files that are to be deleted after a task in a later
      # phase will be moved to be associated with the task after which they are deleted and will be listed as outputs for
      # the phase where they are generated. This ensures that where multiple phases exist, temporary files which cannot be
      # deleted in the makefile in which they are generated are listed as outputs in that makefile, but are listed as
      # intermediate files for the phase in which they are deleted.
      intermediates = {}
  
      # Loop over all tasks.
      for task in self.executionInfo: 
        phase = struct.task[task]
        if task not in intermediates: intermediates[task] = {}
        for subphase in self.executionInfo[task].intermediates:
          if subphase not in intermediates[task]: intermediates[task][subphase] = {}
          for division in self.executionInfo[task].intermediates[subphase]:
            if division not in intermediates[task][subphase]: intermediates[task][subphase][division] = []
            for value in self.executionInfo[task].intermediates[subphase][division]:
              deleteAfterTask = self.fileDeletion[str(value)]
              deletePhase     = struct.task[deleteAfterTask]
  
              # If the file is deleted in another phase, move the intermediate file to be associated with the task after which
              # it is deleted.
              if deletePhase > phase:
                numberDivisions = struct.phaseInformation[deletePhase].numberDivisions
                numberSubphases = struct.phaseInformation[deletePhase].numberSubphases
                if deleteAfterTask not in intermediates: intermediates[deleteAfterTask] = {}
                if subphase not in intermediates[deleteAfterTask]: intermediates[deleteAfterTask][subphase] = {}
                if division not in intermediates[deleteAfterTask][subphase]: intermediates[deleteAfterTask][subphase][division] = []
                self.updateIntermediatesDictionary(deleteAfterTask, numberSubphases, numberDivisions, intermediates, value, subphase, division)
              else:
                numberDivisions = struct.phaseInformation[phase].numberDivisions
                numberSubphases = struct.phaseInformation[phase].numberSubphases
                self.updateIntermediatesDictionary(task, numberSubphases, numberDivisions, intermediates, value, subphase, division)
  
      # Replace the intermediates in the executionInfo with the update values.
      for task in intermediates: self.executionInfo[task].intermediates = deepcopy(intermediates[task])

    # Consolidate subphases and divisions for files in deleteAfterTask.
    deleteAfterTask = {}
    for task in self.deleteAfterTask:
      deleteAfterTask[task] = {}
      phase                 = struct.task[task]
      numberDivisions       = struct.phaseInformation[phase].numberDivisions
      numberSubphases       = struct.phaseInformation[phase].numberSubphases
      for subphase in self.deleteAfterTask[task]:
        for division in self.deleteAfterTask[task][subphase]:
          for value in self.deleteAfterTask[task][subphase][division]:
            self.updateIntermediatesDictionary(task, numberSubphases, numberDivisions, deleteAfterTask, value, subphase, division)

    # Update the stored dictionary.
    self.deleteAfterTask = deleteAfterTask

  # Update the intermediates dictionary based on whether the task is greedy, consolidates or otherwise. e.g. if the task has
  # a single subphase and division, only the subphase = 1 and division = 1 elements are populated.
  def updateIntermediatesDictionary(self, task, numberSubphases, numberDivisions, dictionary, value, subphase, division):

    # If this task only has a single phase and division, all values should be deleted after this execution.
    if numberSubphases == 1:
      if numberDivisions == 1: 
        if 1 not in dictionary[task]: dictionary[task][1] = {}
        if 1 not in dictionary[task][1]: dictionary[task][1][1] = []
        dictionary[task][1][1].append(str(value))
  
      # If the task has a single subphase, but multiple divisions, append values associated with the correct division.
      else:
        if 1 not in dictionary[task]: dictionary[task][1] = {}
        if division not in dictionary[task][1]: dictionary[task][1][division] = []
        dictionary[task][1][division].append(str(value))

    # If the task has a single division and multiple subphases, append values associated with the correct subphase.
    elif numberDivisions == 1: 
      if subphase not in dictionary[task]: dictionary[task][subphase] = {}
      if 1 not in dictionary[task][subphase]: dictionary[task][subphase][1] = []
      dictionary[task][subphase][1].append(str(value))

    # If the task has multiple subphases and divisions, append the value if associated with the correct key.
    else: 
      if subphase not in dictionary[task]: dictionary[task][subphase] = {}
      if division not in dictionary[task][subphase]: dictionary[task][subphase][division] = []
      dictionary[task][subphase][division].append(str(value))

  # If a single makefile is being generated, set the name and open the file.
  def openSingleMakefile(self, pipeline):
    filename = str(pipeline + '-' + self.makefileId) if self.makefileId else str(pipeline)

    # Add a random string to the makefile name. This ensures that if gkno has been executed in a loop,
    # multiple runs of gkno in the same directory for the same pipeline will create makefiles with
    # unique names.
    filename += str('.' + stringOps.getRandomString(8) + '.make')

    # Open the file for writing.
    filehandle = fh.fileHandling.openFileForWriting(ilename)

  # Generate all of the makefile names if multiple makefiles are being generated and open them all for writing.
  def openMakefiles(self, pipeline, randomString, struct):

    # Define the base makefile name.
    basename = str(pipeline + '-' + self.makefileId) if self.makefileId else str(pipeline)

    for phase in struct.phaseInformation:
      divisions = struct.phaseInformation[phase].numberDivisions
      subphases = struct.phaseInformation[phase].numberSubphases

      # If there are multiple phases, add the phase to the filename.
      phaseFilename = basename + str('.phase' + str(phase)) if len(struct.phaseInformation) > 1 else basename

      # Loop over all subphases and divisions.
      for subphase in range(1, subphases + 1):
        for division in range(1, divisions + 1):

          # Generate the filenames if multiple makefiles are being produced.
          if self.isMultipleMakefiles:
            filename = phaseFilename
  
            # If the phase has multiple phases and/or divisions, add these to the filename.
            if subphases > 1: filename += str('.subphase' + str(subphase))
            if divisions > 1: filename += str('.division' + str(division))
 
          # If there is only a single makefile, the name is simply the base name.
          else: filename = basename

          # Add a random string to the makefile name. This ensures that if gkno has been executed in a loop,
          # multiple runs of gkno in the same directory for the same pipeline will create makefiles with
          # unique names.
          filename += str('.' + randomString + '.make')

          # Open the file for writing. If this is a single makefile, this should only happen once.
          if self.isMultipleMakefiles or (phase + subphase + division) == 3:
            filehandle = fh.fileHandling.openFileForWriting(filename)
            self.filenamesList.append(filename)

          # Store the filenames and filehandles in a dictionary, keyed by the ordered combination of the phase,
          # subphase and division..
          key                        = str(phase) + str(subphase) + str(division)
          self.filenames[key]        = filename
          self.filehandles[filename] = filehandle
          self.keys[filename]        = key

    # If there is only a single makefile, store its name and filehandle.
    if not self.isMultipleMakefiles:
      self.singleFilename   = self.filenamesList[0]
      self.singleFilehandle = self.filehandles[self.singleFilename]

  # Add header text to the file.
  def addHeader(self, commitID, date, version, pipeline, sourcePath, toolsPath, resourcesPath):

    # Loop over all makefiles.
    for filename in self.filenamesList:
      filehandle = self.filehandles[filename]

      # Add basic text about the gkno version.
      print('### gkno makefile', file = filehandle)
      print('### Generated using gkno version: ', version, ' (', date, ')', sep = '', file = filehandle)
      print('### gkno commit: ', commitID, sep = '', file = filehandle)
      print('### Pipeline: ', pipeline, sep = '', file = filehandle)
      print(file = filehandle)
      print('### Set the shell to bash.', file = filehandle)
      print('SHELL=/bin/bash', file = filehandle)
      print(file = filehandle)
  
      # Include the paths to tools and resources.
      print('### Paths to tools and resources.', file = filehandle)
      print('GKNO_PATH=', sourcePath, sep = '', file = filehandle)
      print('TOOL_BIN=', toolsPath, sep = '', file = filehandle)
      print('RESOURCES=', resourcesPath, sep = '', file = filehandle)
      print('MAKEFILE_ID=', filename.rsplit('.make', 1)[0], sep = '', file = filehandle)
      print(file = filehandle)
  
      # Define the stdout and stderr.
      print('### Standard output and error files.', file = filehandle)
      print('STDOUT=$(PWD)/$(MAKEFILE_ID).stdout', sep = '', file = filehandle)
      print('STDERR=$(PWD)/$(MAKEFILE_ID).stderr', sep = '', file = filehandle)
      print('COMPLETE_OK=$(PWD)/$(MAKEFILE_ID).ok', sep = '', file = filehandle)
      print('EXECUTED=$(PWD)/$(MAKEFILE_ID).executed', sep = '', file = filehandle)
      print(file = filehandle)
  
      # Remove file on failed execution.
      print('### If the pipeline terminates unexpectedly, delete all files that were in', file = filehandle)
      print('### the process of being generated.', file = filehandle)
      print('.DELETE_ON_ERROR:', file = filehandle)
      print(file = filehandle)
  
      # The paths to the executables are added by phase later.
      print('### Executable paths.', file = filehandle)

  # If a single makefile is being output, find all the unique tools used in the pipeline.
  def addUniqueExecutables(self, graph, struct):
    allTools = []

    # Loop over all phases and all contained task and identify all tools.
    for phase in struct.phaseInformation:
      phaseTools = []
      for task in struct.phaseInformation[phase].tasks:
        tool = graph.getGraphNodeAttribute(task, 'tool')
        if tool in self.toolPaths: phaseTools.append(self.toolPaths[tool])

      # Remove tools that appear multiple times.
      phaseTools = set(phaseTools)

      # If there are multiple phases, write the tools for the phase to all makefiles in that
      # phase.
      if self.isMultipleMakefiles:
        for key in self.filenames:
          if key.startswith(str(phase)):
            filename = self.filenames[key]
            for tool in phaseTools: print(str(tool), file = self.filehandles[filename])
            print(file = self.filehandles[filename])

      # Add the tools for this phase to the list of tools for the pipeline.
      allTools.extend(phaseTools)
 
    # Having colleted all tools, remove duplicates and write to a single makefile, if required.
    if not self.isMultipleMakefiles:
      for tool in list(set(allTools)): print(str(tool), file = self.singleFilehandle)
      print(file = self.singleFilehandle)

  # List phony arguments. This is used solely for the file created on successful execution of the pipeline.
  def addPhony(self):
    for filename in self.filenamesList:
      print('### List all PHONY targets. These are targets that are not actual files.', file = self.filehandles[filename])
      print('.PHONY: DELETE_COMPLETE_OK', filename, file = self.filehandles[filename])
      print(file = self.filehandles[filename])

  # Get the intermediate and output files for the whole pipeline.
  def getAllOutputs(self, struct, randomString):

    # Loop over all the phases, subphases and divisions.
    allIntermediates = []
    allOutputs       = []
    intermediates    = {}
    outputs          = {}
    for phase in struct.phaseInformation:
      subphases = struct.phaseInformation[phase].numberSubphases
      divisions = struct.phaseInformation[phase].numberDivisions
      for subphase in range(1, subphases + 1):
        for division in range(1, divisions + 1):

          # Store the intermediates and outputs, keyed by the phase, subphase and division.
          key = str(phase) + str(subphase) + str(division)

          intermediates[key] = []
          outputs[key]       = []
          for task in struct.phaseInformation[phase].tasks:
            intermediates[key].extend(self.executionInfo[task].intermediates[subphase][division])
            outputs[key].extend(self.executionInfo[task].outputs[subphase][division])

          # Remove output files that are also marked as intermediates.
          outputs[key] = list(set(outputs[key]) - set(intermediates[key]))

          # If there are multiple makefiles, add the intermediate and output files to the relevant
          # makefile.
          if self.isMultipleMakefiles:
            filename   = self.filenames[key]
            filehandle = self.filehandles[filename]
            self.addIntermediateFiles(intermediates[key], outputs[key], filename, filehandle)
            self.addOutputFiles(outputs[key], filehandle)

          # Add the outputs and intermediates to the total lists.
          allOutputs.extend(outputs[key])
          allIntermediates.extend(intermediates[key])

    # Determine if there are duplicate output files.
    duplicates = [x for x, y in collections.Counter(allOutputs).items() if y > 1]
    if len(duplicates) != 0: self.errors.duplicateOutputFiles(duplicates)

    # Add the intermediate and output files to the single makefile, if required.
    if not self.isMultipleMakefiles:
      self.addIntermediateFiles(allIntermediates, allOutputs, self.singleFilename, self.singleFilehandle)
      self.addOutputFiles(allOutputs, self.singleFilehandle)
      outputs[str(111)] = list(set(allOutputs) - set(allIntermediates))

    # Return a list of final outputs.
    return outputs

  # Add intermediate files to the makefile.
  def addIntermediateFiles(self, intermediates, outputs, filename, filehandle):

    # Write intermediate files to the makefile header. Files marked as intermediate are removed during
    # execution of the pipeline. By being marked as intermediate, reexecution of the pipeline will not
    # commence to regenerate the intermediate files.
    print('### The following files are intermediates. If the pipeline is rerun, rules for creating', file = filehandle)
    print('### will not be rerun unless files prior to these rules have been updated.', file = filehandle)
    print('.PRECIOUS: ', filename, end = ' ', file = filehandle)

    # Add all the intermediates to the makefile.
    for intermediate in intermediates: print(intermediate, end = ' ', file = filehandle)
    print(file = filehandle)

    print('.INTERMEDIATE: ', filename, end = ' ', file = filehandle)
    for intermediate in intermediates: print(intermediate, end = ' ', file = filehandle)
    print(file = filehandle)
    print(file = filehandle)

  # Add output files to the makefile.
  def addOutputFiles(self, outputs, filehandle):

    # List all the output files created by this makefile.
    print('### List all of the files that are required outputs of the pipeline.', file = filehandle)
    print('all: DELETE_COMPLETE_OK $(COMPLETE_OK) ', end = '', file = filehandle)

    # Add all the output files to the makefile.
    for output in outputs: print(str(output), end = ' ', file = filehandle)
    print(file = filehandle)
    print(file = filehandle)

  # Prior to pipeline execution, remove the 'ok' file prodiced by a previous successful execution.
  def removeOk(self):
    for filename in self.filenamesList:
      filehandle = self.filehandles[filename]
      print('### Remove the file indicating successful completion of the pipeline. This file needs', file = filehandle)
      print('### to be recreated if the pipeline is rerun to indicate successful completion.', file = filehandle)
      print('DELETE_COMPLETE_OK:', file = filehandle)
      print('\t@rm -f $(EXECUTED)', file = filehandle)
      print('\t@rm -f $(COMPLETE_OK)', file = filehandle)
      print(file = filehandle)

  # Add the command lines to the makefiles.
  def addCommandLines(self, graph, struct, phase, subphase, division):

    # Loop over the tasks for this makefile adding the command lines.
    for task in struct.phaseInformation[phase].tasks:
      isInputStream  = graph.getGraphNodeAttribute(task, 'isInputStream')
      isOutputStream = graph.getGraphNodeAttribute(task, 'isOutputStream')

      # If this task outputs to a stream, no information should be written to the makefiles at this point.
      # All of the tasks that are part of the stream should be processed, so that the list of dependencies
      # and outputs can be constructed properly. If the task does not accept an input stream, then this is
      # the first task in the set of piped tools, so a data structure should be initialised.
      if isOutputStream:
        if not isInputStream: info = streamingInformation()
        self.storeStreamingTaskInformation(info, subphase, division, task, isLast = False)

      # If this task accepts an input stream and isn't outputting to a stream, all of the stored information
      # as well as the information for this task can be written to file.
      elif isInputStream:
        self.storeStreamingTaskInformation(info, subphase, division, task, isLast = True)
        self.writeStreamingInformation(graph, struct, info, phase, subphase, division)

      # If this does not accept a stream or output to a stream, just write the information to the makefile.
      else: self.writeStandardInformation(graph, phase, subphase, division, task)

  # Update the stored information for tasks piped together.
  def storeStreamingTaskInformation(self, info, subphase, division, task, isLast):

    # Add this task to the list of tasks that are streamed together.
    info.tasks.append(task)

    # Update the list of task dependencies. This is all of the dependencies for the current
    # task minus any files that are streamed.
    for dependency in self.executionInfo[task].dependencies[subphase][division]:
      if dependency not in info.streamedFiles and dependency not in info.dependencies: info.dependencies.append(dependency)

    # Now loop over all of the outputs for the task. If the output file is being piped, this
    # should not be included in the list of outputs.
    # FIXME FOR NOW ASSUMING THAT ALL OUTPUTS ARE STREAMED.
    if isLast:
      for output in self.executionInfo[task].outputs[subphase][division]: info.outputs.append(output)
    else:
      for output in self.executionInfo[task].outputs[subphase][division]: info.streamedFiles.append(output)

    # Loop over all of the intermediate files (e.g. the files that can be deleted after this task is
    # complete) and store these files. These will be deleted at the end of the piped tasks.
    for intermediate in self.executionInfo[task].intermediates[subphase][division]:
      if intermediate not in info.streamedFiles and intermediate not in info.intermediates: info.intermediates.append(intermediate)

    # Finally, store the command line for the task.
    for line in self.executionInfo[task].commands[subphase][division]: info.commands.append(line)

  # Write information to the makefile for a set of piped tasks.
  def writeStreamingInformation(self, graph, struct, info, phase, subphase, division):

    # Get the filename and filehandle.
    filename   = self.filenames[str(phase) + str(subphase) + str(division)]
    filehandle = self.filehandles[filename]

    print('### Command line information for the following piped tasks:', file = filehandle)
    print('### ', end = '', file = filehandle)
    for i in range(0, len(info.tasks) - 1): print(info.tasks[i], end = ', ', file = filehandle)
    print(info.tasks[-1], '...', sep = '', file = filehandle)

    # Only include the first output in the rule. If there are additional outputs, these are handled after
    # the rule in the makefile.
    print(info.outputs[0], ':', sep = '', end = ' ', file = filehandle)
    for dependency in info.dependencies: print(dependency, end = ' ', file = filehandle)
    print(file = filehandle)
  
    # Print to screen the tasks being executed.
    print('\t@echo -e "Executing tasks: ', end = '', file = filehandle)
    for i in range(0, len(info.tasks) - 1): print(info.tasks[i], end = ', ', file = filehandle)
    print(info.tasks[-1], '...\c"', sep = '', file = filehandle)
  
    # Print the command line.
    for line in info.commands: print(line, file = filehandle)
  
    # Include an additional rule if the task created multiple output files.
    if len(info.outputs) > 1: self.multipleOutputFiles(filehandle, filename, info, subphase, division)

    # If any files are to be deleted after these tasks, delete them.
    intermediates = []
    for task in info.tasks:
      if task in self.deleteAfterTask:
        for value in self.deleteAfterTask[task][subphase][division]: intermediates.append(value)

    # Delete the files.
    if intermediates:
      print('### Delete intermediate files that are no longer required.', file = filehandle)
      print('\t@echo -e "Deleting temporary files...\\c"', file = filehandle)
      for intermediate in intermediates: print('\t@rm -f ', intermediate, sep = '', file = filehandle)
      print('\t@echo -e "complete."', file = filehandle)
      print(file = filehandle)

  # Write information to the makefile for a task with no streaming.
  def writeStandardInformation(self, graph, phase, subphase, division, task):

    # Get the filename and filehandle.
    filename   = self.filenames[str(phase) + str(subphase) + str(division)]
    filehandle = self.filehandles[filename]

    print('### Command line information for the following task:', file = filehandle)
    print('### ', task, ' (', graph.getGraphNodeAttribute(task, 'tool'), ')', sep = '', file = filehandle)
  
    # Only include the first output in the rule. If there are additional outputs, these are handled after
    # the rule in the makefile.
    print(self.executionInfo[task].outputs[subphase][division][0], ':', sep = '', end = ' ', file = filehandle)
    for dependency in self.executionInfo[task].dependencies[subphase][division]: print(dependency, end = ' ', file = filehandle)
    print(file = filehandle)

    # Print to screen the task being executed.
    print('\t@echo -e "Executing task: ', task, '...\c"', sep = '', file = filehandle)
  
    # Print the command line.
    for line in self.executionInfo[task].commands[subphase][division]: print(line, file = filehandle)

    # Include an additional rule if the task created multiple output files.
    if len(self.executionInfo[task].outputs[subphase][division]) > 1:
      self.multipleOutputFiles(filehandle, filename, self.executionInfo[task], subphase, division)

    # If any files are to be deleted after this task, delete them.
    if task in self.deleteAfterTask:
      intermediates = []

      # If the task is greedy, delete all files, otherwise just the files associated with this subphase.
      if graph.getGraphNodeAttribute(task, 'isGreedy'):
        for subphase in self.deleteAfterTask[task]:
          for division in self.deleteAfterTask[task][subhpase]:
            for value in self.deleteAfterTask[task][subhpase][division]: intermediates.append(value)
      else: intermediates = self.deleteAfterTask[task][subphase][division]

      # If there are files to delete, include instructions to delete them.
      if intermediates:
        print('### Delete intermediate files that are no longer required.', file = filehandle)
        print('\t@echo -e "Deleting temporary files...\\c"', file = filehandle)
        for intermediate in intermediates: print('\t@rm -f ', intermediate, sep = '', file = filehandle)
        print('\t@echo -e "complete."', file = filehandle)
        print(file = filehandle)

  # output is included in the rule for the additional task.
  def multipleOutputFiles(self, filehandle, filename, data, subphase, division):
    print('### Rule for checking that all outputs of previous task exist.', file = filehandle)
    for counter in range(1, len(data.outputs[subphase][division]) - 1):
      print(data.outputs[subphase][division][counter], end = ' ', file = filehandle)
    print(data.outputs[subphase][division][-1], end = ': ', file = filehandle)
    for dependency in data.dependencies[subphase][division]: print(dependency, end = ' ', file = filehandle)

    # Add the primaryOutput to the list of dependencies. This is the file that is listed as the output for
    # the rule. If running with multiple threads and none of the files exist, the original rule is executed
    # since the output file does not exist. This rule for the additional outputs is the executed in parallel
    # since none of these additional files exist either. By including the primaryOutput as a dependency, we
    # ensure that the original rule gets to run first and this check isn't performed until it has been
    # completed.
    print(data.outputs[subphase][division][0], file = filehandle)
    print('\t@if test -f $@ || test -d $@; then \\', file = filehandle)
    print('\t  touch $@; \\', file = filehandle)
    print('\telse \\', file = filehandle)
    print('\t  rm -f ', data.outputs[subphase][division][0], "; \\", sep = '', file = filehandle)
    print('\t  $(MAKE) --no-print-directory -f $(PWD)/', filename, ' ', data.outputs[subphase][division][0], '; \\', sep = '', file = filehandle)
    print('\tfi', file = filehandle)
    print(file = filehandle)

  # Write the final instructions to the makefile.
  def completeFile(self, outputs):
 
    # Loop over all files and add the final text to them all.
    for filename in self.filenamesList:
      filehandle = self.filehandles[filename]

      # If there is only a single makefile, set the key to 111, otherwise use the filename to find the key.
      key = str(111) if not self.isMultipleMakefiles else self.keys[filename]

      # Prior to closing the file, include instructions for generating an 'ok' file indicating that the
      # makefile was successfully executed and delete the makefile.
      print('### Generate a file indicating successful execution of makefile', file = filehandle)
      print('$(COMPLETE_OK): ', end = '', file = filehandle)
  
      # Add all of the outputs generated by this makefile to the list of dependencies. The 'ok' file is
      # only created if the pipeline ran successfully and generated everything required.
      for filename in outputs[key]: print(filename, end = ' ', file = filehandle)
      print(file = filehandle)
      print('\t@rm -f $(MAKEFILE_ID).make', file = filehandle)

      # If any of the rules were executed, the file defined by $(EXECUTED) will have been created. If this
      # file does not exist, nothing was executed. This will result if all the files already existed and
      # make determined that there was no need to execute any rules. If this is the case, inform the user.
      print('\t@if test ! -f $(EXECUTED); then \\', file = filehandle)
      print('\t  echo \'===================================\'; \\', file = filehandle)
      print('\t  echo \'  WARNING: No new files generated.\'; \\', file = filehandle)
      print('\t  echo \'===================================\'; \\', file = filehandle)
      print('\t  echo ; \\', file = filehandle)
      print('\t  echo \'All required output files already exist, so none of the tasks in the pipeline were executed.\'; \\', file = filehandle)
      print('\t  echo \'To force execution of the pipeline remove output files prior to execution of gkno.\'; \\', file = filehandle)
      print('\telse \\', file = filehandle)
      print('\t  touch $(COMPLETE_OK); \\', file = filehandle)
      print('\tfi', file = filehandle)
      print('\t@rm -f $(EXECUTED)', file = filehandle)

  # Close the makefiles.
  def closeFiles(self):
    for filename in self.filenamesList:
      filehandle = self.filehandles[filename]
      fh.fileHandling.closeFile(filehandle)

  # Return the argument to be written to the command line (and consequently, that stored in the commands
  # data structure). It is usually the case that the gkno argument does not correspond to the tool
  # argument.
  def getToolArgument(self, graph, task, nodeId, isInput):

    # Determine if a particular set of instructions was requested. If not, use the default set.
    inputSet  = graph.getGraphNodeAttribute(task, 'inputStreamInstructionSet')
    outputSet = graph.getGraphNodeAttribute(task, 'outputStreamInstructionSet')

    # Get the correct set of input stream instructions.
    inputInstructions  = graph.getArgumentAttribute(nodeId, task, 'inputStreamInstructions')
    outputInstructions = graph.getArgumentAttribute(task, nodeId, 'outputStreamInstructions')

    # Determine streaming instructions, beginning with if this is an input accepting a stream.
    if graph.getGraphNodeAttribute(task, 'isInputStream') and inputInstructions:

      # Get the correct set of stream instructions.
      if inputSet not in inputInstructions: pce.pipelineErrors().invalidStreamSet(graph.pipeline, task, inputSet, inputInstructions.keys(), isInput = True)

      # If the argument should be omitted.
      if inputInstructions[inputSet]['argument'] == 'omit': return None
 
      # Return the supplied value to use as the argument.
      else: return str(inputInstructions[inputSet]['argument'])

    # Now handle outputting to a stream.
    elif graph.getGraphNodeAttribute(task, 'isOutputStream') and outputInstructions:

      # Get the correct set of stream instructions.
      if outputSet not in outputInstructions: pce.pipelineErrors().invalidStreamSet(graph.pipeline, task, outputSet, outputInstructions.keys(), isInput = False)
  
      # Check for the different allowed modifications to the argument. If the argument is listed as omit,
      # the argument should be omitted from the command line (not replaced with another value). In this
      # case, return None.
      if outputInstructions[outputSet]['argument'] == 'omit': return None
  
      # If the instructions are none of the above, the argument should be replaced with the supplied value.
      # In this case, return the value supplied.
      else: return str(outputInstructions[outputSet]['argument'])

    # Otherwise, use the other instructions.
    else:
  
      # If the argument is for an input file.
      if isInput:
        commandLineArgument = graph.getArgumentAttribute(nodeId, task, 'commandLineArgument')
        modifyArgument      = graph.getArgumentAttribute(nodeId, task, 'modifyArgument')
  
      # And if the argument is for an output file.
      else: 
        commandLineArgument = graph.getArgumentAttribute(task, nodeId, 'commandLineArgument')
        modifyArgument      = graph.getArgumentAttribute(task, nodeId, 'modifyArgument')
  
      # Return the argument to be used on the command line.
      if modifyArgument == 'omit': return None

      # If the output should be redirected to stdout, there should be no command, just the redirection.
      elif modifyArgument == 'stdout': return '>>'
      else: return commandLineArgument

  #######################################################
  ### Static methods for getting makefile information ###
  #######################################################

  # If the input/output is a stream, determine how the value should be written to the command line.
  @staticmethod
  def getStreamValue(graph, source, target, value, isInput, isStub):
    if isInput:
      inputSet     = graph.getGraphNodeAttribute(target, 'inputStreamInstructionSet')
      instructions = graph.getArgumentAttribute(source, target, 'inputStreamInstructions')[inputSet]
    else:
      outputSet    = graph.getGraphNodeAttribute(source, 'outputStreamInstructionSet')
      instructions = graph.getArgumentAttribute(source, target, 'outputStreamInstructions')[outputSet]

    # Return the value based on the instructions.
    if instructions['value'] == 'omit': return None

    # If the instructions indicate that the value should be left as is, return the original value.
    elif instructions['value'] == 'keep': return value

    # If none of the above instructions are set, return the value supplied in the instructions. This is
    # what will be used in place of the value.
    else: return str(instructions['value'])

  # Similar method to the getToolArgument except for the associated value.
  @staticmethod
  def getValue(graph, source, target, value, isInput, isStub, stubExtension):

    # If the argument is for an input file.
    modifyValue = graph.getArgumentAttribute(source, target, 'modifyValue')

    # Check if the value should be included in quotation marks.
    inQuotations = graph.getArgumentAttribute(source, target, 'includeInQuotations')

    # If this is a stub, strip off the extension if it has been attached.
    if isStub:
      if not graph.getArgumentAttribute(source, target, 'isPrimaryStubNode'): return None
      else: 
        try: updatedValue = value.rstrip(stubExtension)
        except: updatedValue = value
        updatedValue = updatedValue.rstrip('.') if updatedValue.endswith('.') else updatedValue
        if inQuotations: return str('"' + updatedValue + '"')
        else: return updatedValue

    # If this is not a stub, return the argument to be used on the command line.
    if modifyValue == 'omit': return None

    # If a command has been supplied to replace the value, modify the value accordingly.
    elif modifyValue == 'command': 
      instructions = graph.getArgumentAttribute(source, target, 'valueCommand')
      command      = instructions['command']
  
      # If the field 'apply to extensions' is set, only apply this command if the value has
      # one of the specified extensions.
      applyCommand = True
      if 'apply to extensions' in instructions:
        isMatchedExtension = False
        for extension in instructions['apply to extensions']:
          if value.endswith(extension):
            isMatchedExtension = True
            break
        if not isMatchedExtension: applyCommand = False

      # If the command is to be used replaced, return the command with 'VALUE' replaced with the
      # value.
      if applyCommand: return str(command).replace('VALUE', value)
      else: return value

    # Include the value in quotations, if requested.
    elif inQuotations: return str('"' + value + '"')

    # Otherwise, just return the original value.
    else: return value

  # Build a line of the command line.
  @staticmethod
  def buildLine(argument, delimiter, value):
    hasValue = False if not value and value != 0 else True

    # If neither the argument or the value are populated, return None.
    if not argument and not hasValue: return None

    # If the value is defined, but the argument is not, this is a tool that does not use arguments on the
    # command line and so the command should be the value only.
    elif not argument: return '\t' + str(value) + ' \\'

    # If only the argument is defined, this is a flag, so only the argument is returned.
    elif not hasValue: return '\t' + str(argument) + ' \\'

    # Finally, if both are defined, return the correctly delimited argument, value pair.
    else: return '\t' + str(argument) + str(delimiter) + str(value) + ' \\'
    line = '\t' + str(argument) + str(delimiter) + str(value) + ' \\'
